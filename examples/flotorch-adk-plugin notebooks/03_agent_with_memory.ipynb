{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Flotorch ADK - Flotorch Memory Service Example\n",
        "\n",
        "This notebook demonstrates how to integrate Flotorch Memory Service with ADK agents.\n",
        "Shows how to store and retrieve conversations using Flotorch Memory Service.\n",
        "\n",
        "## Key Features\n",
        "- Flotorch Memory Service integration\n",
        "- Automatic conversation storage  \n",
        "- Memory-aware agent responses\n",
        "\n",
        "## Requirements\n",
        "- FLOTORCH_API_KEY environment variable\n",
        "- FLOTORCH_BASE_URL environment variable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Environment setup complete\n"
          ]
        }
      ],
      "source": [
        "# Setup and imports\n",
        "import asyncio\n",
        "import os\n",
        "import sys\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "print(\"✓ Environment setup complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Flotorch ADK imports successful\n"
          ]
        }
      ],
      "source": [
        "# Flotorch ADK imports\n",
        "from flotorch.adk.llm import FlotorchADKLLM\n",
        "from flotorch.adk.memory import FlotorchMemoryService\n",
        "from google.adk.agents import LlmAgent\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk import Runner\n",
        "from google.genai import types\n",
        "from google.adk.tools import load_memory\n",
        "\n",
        "print(\"✓ Flotorch ADK imports successful\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "App Name: flotorch_memory_service_example\n",
            "User ID: flotorch_user_123\n",
            "Memory Provider: memo-provider\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "APP_NAME = \"flotorch_memory_service_example\"\n",
        "USER_ID = \"flotorch_user_123\"\n",
        "MEMORY_PROVIDER = \"memo-provider\"\n",
        "\n",
        "print(f\"App Name: {APP_NAME}\")\n",
        "print(f\"User ID: {USER_ID}\")\n",
        "print(f\"Memory Provider: {MEMORY_PROVIDER}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Flotorch LLM model created\n"
          ]
        }
      ],
      "source": [
        "# Create Flotorch LLM model\n",
        "model = FlotorchADKLLM(\n",
        "    model_id=\"openai/gpt-4o-mini\",\n",
        "    api_key=os.getenv(\"FLOTORCH_API_KEY\"),\n",
        "    base_url=os.getenv(\"FLOTORCH_BASE_URL\"),\n",
        ")\n",
        "\n",
        "print(\"✓ Flotorch LLM model created\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Flotorch Memory Service initialized\n"
          ]
        }
      ],
      "source": [
        "# Initialize Flotorch Memory Service\n",
        "flotorch_memory_service = FlotorchMemoryService(\n",
        "    name=MEMORY_PROVIDER,\n",
        "    api_key=os.getenv(\"FLOTORCH_API_KEY\"),\n",
        "    base_url=os.getenv(\"FLOTORCH_BASE_URL\"),\n",
        ")\n",
        "\n",
        "print(\"✓ Flotorch Memory Service initialized\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Flotorch agent with memory tool created\n"
          ]
        }
      ],
      "source": [
        "# Create Flotorch agent with memory tool\n",
        "agent = LlmAgent(\n",
        "    name=\"Flotorch_Memory_Assistant\",\n",
        "    description=\"A Flotorch AI assistant with Flotorch Memory Service integration\",\n",
        "    instruction=\"You are Flotorch AI assistant with memory capabilities. Use your memory to provide contextual responses.\",\n",
        "    model=model,\n",
        "    tools=[load_memory],  # Memory tool for accessing Flotorch Memory Service\n",
        ")\n",
        "\n",
        "print(\"✓ Flotorch agent with memory tool created\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Runner setup with memory service complete\n"
          ]
        }
      ],
      "source": [
        "# Setup runner with Flotorch Memory Service\n",
        "session_service = InMemorySessionService()\n",
        "runner = Runner(\n",
        "    agent=agent,\n",
        "    app_name=APP_NAME,\n",
        "    session_service=session_service,\n",
        "    memory_service=flotorch_memory_service  # Flotorch Memory Service integration\n",
        ")\n",
        "\n",
        "print(\"✓ Runner setup with memory service complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Helper function defined\n"
          ]
        }
      ],
      "source": [
        "# Helper function to send messages\n",
        "def run_single_turn(query, session_id, user_id):\n",
        "    \"\"\"Send message to Flotorch agent with memory service support.\"\"\"\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
        "    events = runner.run(user_id=user_id, session_id=session_id, new_message=content)\n",
        "\n",
        "    for event in events:\n",
        "        if event.is_final_response():\n",
        "            if event.content and event.content.parts:\n",
        "                return event.content.parts[0].text\n",
        "    \n",
        "    return \"Sorry, I couldn't process that.\"\n",
        "\n",
        "print(\"✓ Helper function defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flotorch agent with Memory Service ready! Session: 2c0216a9-1b1b-456b-bad4-28b97ea033bc\n",
            "The agent can now access and store memories using Flotorch Memory Service\n",
            "\n",
            "User: Hello! My name is John and I work as a software engineer.\n",
            "Flotorch AI: Hello, John! It's great to meet you. I see that you work as a software engineer. By the way, do you have any pets?\n"
          ]
        }
      ],
      "source": [
        "# Create session and test memory-enabled agent\n",
        "async def test_memory_agent():\n",
        "    session = await runner.session_service.create_session(\n",
        "        app_name=APP_NAME,\n",
        "        user_id=USER_ID,\n",
        "    )\n",
        "    \n",
        "    print(f\"Flotorch agent with Memory Service ready! Session: {session.id}\")\n",
        "    print(\"The agent can now access and store memories using Flotorch Memory Service\")\n",
        "    \n",
        "    # Test with a simple message\n",
        "    test_message = \"Hello! My name is John and I work as a software engineer.\"\n",
        "    response = run_single_turn(test_message, session.id, USER_ID)\n",
        "    \n",
        "    print(f\"\\nUser: {test_message}\")\n",
        "    print(f\"Flotorch AI: {response}\")\n",
        "    \n",
        "    return session\n",
        "\n",
        "# Run the test\n",
        "session = await test_memory_agent()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Conversation with Memory ===\n",
            "You: I love hiking and have a pet dog named Max.\n",
            "Flotorch AI: That's awesome! Hiking is a great way to enjoy nature, and having a dog like Max must make it even more fun. Just to clarify, I have a note that you have a dog named Rocky. Is there a mix-up, or do you have two dogs?\n",
            "\n",
            "--------------------------------------------------\n",
            "You: What's my job?\n",
            "Flotorch AI: You work as a software engineer.\n",
            "\n",
            "--------------------------------------------------\n",
            "You: What's my dog's name?\n",
            "Flotorch AI: You mentioned that your dog's name is Max, but I also have a note that you have a dog named Rocky. Could you clarify if you have two dogs or if there's been a mix-up?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"You mentioned that your dog's name is Max, but I also have a note that you have a dog named Rocky. Could you clarify if you have two dogs or if there's been a mix-up?\""
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Interactive chat function with memory\n",
        "def chat_with_memory(message):\n",
        "    \"\"\"Simple function to chat with the memory-enabled agent.\"\"\"\n",
        "    response = run_single_turn(message, session.id, USER_ID)\n",
        "    print(f\"You: {message}\")\n",
        "    print(f\"Flotorch AI: {response}\")\n",
        "    return response\n",
        "\n",
        "# Have a conversation that demonstrates memory\n",
        "print(\"=== Conversation with Memory ===\")\n",
        "chat_with_memory(\"I love hiking and have a pet dog named Max.\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*50)\n",
        "chat_with_memory(\"What's my job?\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*50)\n",
        "chat_with_memory(\"What's my dog's name?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Storing conversation in Flotorch Memory Service...\n",
            "✓ Conversation successfully stored in Flotorch Memory Service!\n"
          ]
        }
      ],
      "source": [
        "# Store conversation in Flotorch Memory Service\n",
        "async def store_conversation():\n",
        "    print(\"Storing conversation in Flotorch Memory Service...\")\n",
        "    \n",
        "    completed_session = await runner.session_service.get_session(\n",
        "        app_name=APP_NAME, \n",
        "        user_id=USER_ID, \n",
        "        session_id=session.id\n",
        "    )\n",
        "    \n",
        "    await flotorch_memory_service.add_session_to_memory(completed_session)\n",
        "    print(\"✓ Conversation successfully stored in Flotorch Memory Service!\")\n",
        "\n",
        "# Store the conversation\n",
        "await store_conversation()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Memory Recall Demo\n",
        "\n",
        "Now let's create a new session to test if the agent can recall information from the stored memory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New session started: a5c6eb33-34d6-44e3-a51a-c2845f5a97a9\n",
            "Testing memory recall...\n",
            "\n",
            "User: Do you remember what I told you about my job and pet?\n",
            "Flotorch AI: You mentioned that your name is John, and you work as a software engineer. You also have a pet dog named Max, and you love hiking.\n"
          ]
        }
      ],
      "source": [
        "# Test memory recall with new session\n",
        "async def test_memory_recall():\n",
        "    new_session = await runner.session_service.create_session(\n",
        "        app_name=APP_NAME,\n",
        "        user_id=USER_ID,\n",
        "    )\n",
        "    \n",
        "    print(f\"New session started: {new_session.id}\")\n",
        "    print(\"Testing memory recall...\")\n",
        "    \n",
        "    # Test if agent remembers previous conversation\n",
        "    recall_message = \"Do you remember what I told you about my job and pet?\"\n",
        "    response = run_single_turn(recall_message, new_session.id, USER_ID)\n",
        "    \n",
        "    print(f\"\\nUser: {recall_message}\")\n",
        "    print(f\"Flotorch AI: {response}\")\n",
        "    \n",
        "    return new_session\n",
        "\n",
        "# Test memory recall\n",
        "new_session = await test_memory_recall()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "- ✓ Setting up Flotorch Memory Service\n",
        "- ✓ Creating memory-enabled agents with load_memory tool\n",
        "- ✓ Storing conversations in Flotorch Memory Service\n",
        "- ✓ Memory recall across different sessions\n",
        "- ✓ Building memory-aware AI applications\n",
        "\n",
        "You can now use `chat_with_memory(\"your message\")` to continue the conversation with memory!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}