{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b515f99",
   "metadata": {},
   "source": [
    "# Building a LangChain Agent with Long-Term Memory via Flotorch\n",
    "\n",
    "This notebook demonstrates how to build an advanced LangChain agent with long-term memory capabilities using the Flotorch platform. This allows the agent to recall information from previous, separate interactions.\n",
    "\n",
    "### Key Concepts:\n",
    "- **Long-Term Memory**: Provided by `FlotorchLangChainMemory` for persistent knowledge across all sessions.\n",
    "- **`AgentExecutor` and `ChatPromptTemplate`**: Core LangChain components configured to leverage the memory system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7582447",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "The following cells install the necessary packages, configure API credentials, and import the required components from Flotorch and LangChain, including those needed for external memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef10cef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install flotorch langchain package\n",
    "%pip install  flotorch[langchain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f87968",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOTORCH_API_KEY = \"<flotorch api key>\"\n",
    "FLOTORCH_BASE_URL = \"https://qa-gateway.flotorch.cloud\"\n",
    "FLOTORCH_MODEL = \"<flotorch model>\"\n",
    "USER_ID = \"flotorch_user_001\"\n",
    "APP_ID = \"flotorch_app_001\"\n",
    "MEMORY_PROVIDER = \"<flotorch memory provider>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25875af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LangChain and related modules\n",
    "from flotorch.langchain.llm import FlotorchLangChainLLM\n",
    "from flotorch.langchain.memory import FlotorchLangChainMemory\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "print(\"Imported necessary libraries successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1014b1f5",
   "metadata": {},
   "source": [
    "## 2. Model Configuration\n",
    "\n",
    "We initialize the `FlotorchLangChainLLM` which will act as the brain for our agent, enabling it to process information and make decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17dbc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  =  FlotorchLangChainLLM(\n",
    "        model_id=FLOTORCH_MODEL,\n",
    "        api_key=FLOTORCH_API_KEY,\n",
    "        base_url=FLOTORCH_BASE_URL,\n",
    "    )\n",
    "print(\"FlotorchLLM initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530f5ad6",
   "metadata": {},
   "source": [
    "## 3. Memory Configuration\n",
    "\n",
    "This is where we set up the agent's memory system. \n",
    "\n",
    "- **Long-Term Memory**: Uses `FlotorchLangChainMemory` to store and retrieve key information across different sessions, acting as the agent's persistent knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea992db",
   "metadata": {},
   "outputs": [],
   "source": [
    "longterm_memory = FlotorchLangChainMemory(\n",
    "    api_key=FLOTORCH_API_KEY,\n",
    "    base_url=FLOTORCH_BASE_URL,\n",
    "    name = MEMORY_PROVIDER,\n",
    "    user_id = USER_ID,\n",
    "    app_id = APP_ID\n",
    ")\n",
    "\n",
    "print(\"short_term_memory initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2753f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def analyze_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyze text and provide comprehensive statistics.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to analyze\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted text analysis with statistics\n",
    "    \"\"\"\n",
    "    word_count = len(text.split())\n",
    "    char_count = len(text)\n",
    "    char_count_no_spaces = len(text.replace(' ', ''))\n",
    "    sentences = text.count('.') + text.count('!') + text.count('?')\n",
    "    \n",
    "    return f\"\"\"Text Analysis:\n",
    "- Words: {word_count}\n",
    "- Characters (with spaces): {char_count}\n",
    "- Characters (without spaces): {char_count_no_spaces}\n",
    "- Sentences: {sentences}\"\"\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a city. Available cities: New York, London, Tokyo, Paris.\"\"\"\n",
    "    city = city.lower().strip()\n",
    "\n",
    "    weather_info = {\n",
    "        \"new york\": \"Sunny, 72째F, Humidity: 45%\",\n",
    "        \"london\": \"Cloudy, 15째C, Humidity: 70%\",\n",
    "        \"tokyo\": \"Rainy, 25째C, Humidity: 80%\",\n",
    "        \"paris\": \"Partly cloudy, 18째C, Humidity: 60%\"\n",
    "    }\n",
    "\n",
    "    if city in weather_info:\n",
    "        return f\"Weather in {city.title()}: {weather_info[city]}\"\n",
    "    else:\n",
    "        return f\"I don't have weather data for '{city}'. Try: New York, London, Tokyo, or Paris.\"\n",
    "\n",
    "tools = [analyze_text, weather]\n",
    "\n",
    "print(\"Custom tool defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ca4f7b",
   "metadata": {},
   "source": [
    "## 4. Agent and Prompt Configuration\n",
    "\n",
    "We define the `Agent` logic and `ChatPromptTemplate` with a goal that explicitly instructs it to use its memory capabilities to provide accurate and context-aware responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae0cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Agent\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a helpful assistant with access to tools for calculations, weather, and information search.\n",
    "    Use the appropriate tool when needed, or answer directly if you can.\n",
    "    Keep your responses clear and concise.\n",
    "    \n",
    "    Memory context: {longterm_history}\"\"\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\",\"{agent_scratchpad}\"),\n",
    "])\n",
    "\n",
    "agent = create_openai_functions_agent(model,tools,prompt)\n",
    "\n",
    "print(f\"Agent is created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd5edc",
   "metadata": {},
   "source": [
    "## 5. Agent Executor Assembly with Memory\n",
    "\n",
    "The `AgentExecutor` is assembled with the agent, tools, and crucially, the `longterm_memory` module. This equips the agent with a persistent memory capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2c8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory = longterm_memory,\n",
    "    verbose=False,\n",
    "    handle_parsing_errors=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8e89ad",
   "metadata": {},
   "source": [
    "## 6. Interactive Chat\n",
    "\n",
    "Start a chat session to interact with the agent. Test its ability to recall information you provide from facts it may have learned in previous runs (long-term). Type 'exit' to end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f82aaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    \n",
    "    user_query = input(\"user: \")\n",
    "\n",
    "    if user_query.lower().strip() == \"exit\":\n",
    "        break\n",
    "    print(f\"User: {user_query}\")\n",
    "    response = agent_executor.invoke({\"input\":user_query})\n",
    "    print(f\"Assistant: {response['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2a7906",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook detailed the implementation of a sophisticated AI agent equipped with long-term memory.  \n",
    "By leveraging **Flotorch's infrastructure**, we created an agent that retains and recalls information across separate sessions.\n",
    "\n",
    "### Key Achievements\n",
    "\n",
    "- **Persistent Memory** \n",
    "  Successfully integrated `FlotorchLangChainMemory` for persistent, long-term knowledge.\n",
    "\n",
    "- **Enhanced Agent Intelligence** \n",
    "  The agent demonstrated its ability to recall facts from a knowledge base established in previous interactions, leading to more intelligent and informed responses.\n",
    "\n",
    "- **Comprehensive Solution** \n",
    "  This long-term memory approach provides a powerful template for building advanced agents capable of complex, ongoing, and context-rich dialogues.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
