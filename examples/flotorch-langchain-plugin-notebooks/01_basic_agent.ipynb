{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Custom Agent with Flotorch and LangChain\n",
    "\n",
    "This notebook demonstrates how to build and run a simple AI agent using the Flotorch platform and the LangChain framework. The agent will be equipped with custom tools to perform specific functions.\n",
    "\n",
    "### Key Objectives:\n",
    "- Install the required Flotorch package.\n",
    "- Define custom tools for the agent.\n",
    "- Configure an agent using a prompt template and bind it to the tools.\n",
    "- Utilize the `FlotorchLangChainLLM` to power the agent's reasoning capabilities.\n",
    "- Assemble and run the agent workflow using an `AgentExecutor`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Imports\n",
    "\n",
    "The following cells handle the complete setup of the environment. This includes:\n",
    "1. **Installing** the necessary Flotorch SDK package.\n",
    "2. **Importing** essential libraries.\n",
    "3. **Configuring** the API credentials and model endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install flotorch langchain package\n",
    "%pip install  flotorch[langchain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOTORCH_API_KEY = \"<flotorch api key>\"\n",
    "FLOTORCH_BASE_URL = \"https://qa-gateway.flotorch.cloud\"\n",
    "FLOTORCH_MODEL = \"<flotorch model>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LangChain and related modules\n",
    "from flotorch.langchain.llm import FlotorchLangChainLLM\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "print(\"Imported necessary libraries successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Defining a Custom Tool\n",
    "\n",
    "To extend the agent's capabilities, we define custom tools. The `@tool` decorator from LangChain transforms a standard Python function into a tool that the agent can utilize. This example creates an `analyze_text` tool, which takes a string as input and returns a statistical analysis. The function's docstring serves as its description, helping the agent understand how and when to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def analyze_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyze text and provide comprehensive statistics.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to analyze\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted text analysis with statistics\n",
    "    \"\"\"\n",
    "    word_count = len(text.split())\n",
    "    char_count = len(text)\n",
    "    char_count_no_spaces = len(text.replace(' ', ''))\n",
    "    sentences = text.count('.') + text.count('!') + text.count('?')\n",
    "    \n",
    "    return f\"\"\"Text Analysis:\n",
    "- Words: {word_count}\n",
    "- Characters (with spaces): {char_count}\n",
    "- Characters (without spaces): {char_count_no_spaces}\n",
    "- Sentences: {sentences}\"\"\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a city. Available cities: New York, London, Tokyo, Paris.\"\"\"\n",
    "    city = city.lower().strip()\n",
    "\n",
    "    weather_info = {\n",
    "        \"new york\": \"Sunny, 72째F, Humidity: 45%\",\n",
    "        \"london\": \"Cloudy, 15째C, Humidity: 70%\",\n",
    "        \"tokyo\": \"Rainy, 25째C, Humidity: 80%\",\n",
    "        \"paris\": \"Partly cloudy, 18째C, Humidity: 60%\"\n",
    "    }\n",
    "\n",
    "    if city in weather_info:\n",
    "        return f\"Weather in {city.title()}: {weather_info[city]}\"\n",
    "    else:\n",
    "        return f\"I don't have weather data for '{city}'. Try: New York, London, Tokyo, or Paris.\"\n",
    "\n",
    "tools = [analyze_text, weather]\n",
    "\n",
    "print(\"Custom tool defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuring the Language Model\n",
    "\n",
    "The agent requires a Large Language Model (LLM) to act as its brain. We instantiate `FlotorchLangChainLLM`, passing our API credentials and the desired model ID. This object serves as the bridge between our LangChain agent and the powerful reasoning capabilities of the Flotorch platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  =  FlotorchLangChainLLM(\n",
    "        model_id=FLOTORCH_MODEL,\n",
    "        api_key=FLOTORCH_API_KEY,\n",
    "        base_url=FLOTORCH_BASE_URL,\n",
    "    )\n",
    "print(\"FlotorchLLM initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating the Agent\n",
    "\n",
    "With the tool and LLM configured, we now define the agent's core logic. This involves two key LangChain components:\n",
    "\n",
    "- **Prompt Template**: We use `ChatPromptTemplate` to structure the instructions given to the LLM. This template defines the agent's persona (e.g., 'a helpful assistant'), includes placeholders for user input (`{input}`) and intermediate steps (`agent_scratchpad`), and guides the agent's behavior.\n",
    "- **Agent**: We use the `create_openai_functions_agent` function to bind the LLM, the tools, and the prompt together. This function creates the agent logic that can decide which tool to use based on the user's input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a helpful assistant with access to tools for calculations, weather, and information search.\n",
    "    Use the appropriate tool when needed, or answer directly if you can.\n",
    "    Keep your responses clear and concise.\"\"\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "\n",
    "agent = create_openai_functions_agent(model,tools,prompt)\n",
    "\n",
    "print(f\"Agent is created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Running the Agent with an Executor\n",
    "\n",
    "The final step is to create a runtime environment for our agent. In LangChain, this is handled by the `AgentExecutor`. The `AgentExecutor` takes the agent and the tools as input and is responsible for executing the agent's decisions. It calls the agent, determines which tool to use, executes that tool, and passes the result back to the agent to formulate a final response. We start the process by calling the `invoke()` method with the user's input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=False,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "user_input = input(\"user: \")\n",
    "print(f\"User: {user_input}\")\n",
    "response = agent_executor.invoke({\"input\":user_input})\n",
    "print(f\"Assistant: {response['output']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the end-to-end process of creating a functional AI agent using the Flotorch ADK and LangChain. \n",
    "\n",
    "The key components included:\n",
    "\n",
    "1. **Custom Tool Implementation**: A Python function was seamlessly converted into a usable tool for the agent using LangChain's `@tool` decorator.\n",
    "2. **Model Configuration**: The `FlotorchLangChainLLM` was configured to provide the agent with its reasoning ability.\n",
    "3. **Agent Creation**: A prompt template (`ChatPromptTemplate`) and an agent constructor (`create_openai_functions_agent`) were used to define the agent's behavior and access to tools.\n",
    "4. **Agent Execution**: The `AgentExecutor` was used to run the agent, orchestrating the interaction between the LLM and the custom tools to produce the final output.\n",
    "    \n",
    "This example showcases the power and flexibility of the Flotorch platform for building customized, tool-augmented AI agents with LangChain.\n",
    "   \n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
