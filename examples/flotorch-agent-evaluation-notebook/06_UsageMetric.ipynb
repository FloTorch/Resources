{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "gHc0ySiFUlKQ",
      "metadata": {
        "id": "gHc0ySiFUlKQ"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://drive.google.com/drive/folders/1IrwoNrb3AWLAhAqjlAkJNYa39p9eT9ui?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e0202c9",
      "metadata": {
        "id": "5e0202c9"
      },
      "source": [
        "# Flotorch Agent Usage Metric Evaluation (News Summary Agent Use Case)\n",
        "\n",
        "This notebook demonstrates how to measure and analyze the **usage and cost metrics** of a **News Summary Agent** built with **Flotorch ADK** using the **Flotorch Eval** framework.\n",
        "\n",
        "The **News Summary Agent** fetches and summarizes the latest news using news APIs (e.g., NewsAPI). The evaluation relies on **OpenTelemetry Traces** generated during the agent's run to provide a detailed breakdown of token usage and costs across all operations (LLM calls, tool execution, etc.).\n",
        "\n",
        "---\n",
        "\n",
        "## Key Concepts\n",
        "\n",
        "* **News Summary Agent**: An agent designed to fetch and summarize the latest news articles from various sources.\n",
        "* **OpenTelemetry Traces**: Detailed records of the agent's execution steps (spans) used to measure token usage and costs for different operations.\n",
        "* **UsageMetric**: A Flotorch Eval metric that extracts and summarizes usage information (tokens, costs) from the execution traces (agent trajectories). The evaluation metric used is **usage_summary**.\n",
        "\n",
        "---\n",
        "\n",
        "### Architecture Overview\n",
        "\n",
        "![Workflow Diagram](diagrams/06_UsageMetric_Workflow_Diagram.drawio.png)\n",
        "*Figure 2: Detailed workflow diagram showing the step-by-step process of usage metric evaluation from agent execution through trace collection to metric computation.*\n",
        "\n",
        "---\n",
        "\n",
        "## Requirements\n",
        "\n",
        "* Flotorch account with configured models.\n",
        "* Valid Flotorch API key and gateway base URL.\n",
        "* Agent configured with OpenTelemetry tracing enabled.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7183a218",
      "metadata": {},
      "source": [
        "## Agent Setup in Flotorch Console\n",
        "\n",
        "**Important**: Before running this notebook, you need to create an agent in the Flotorch Console. This section provides step-by-step instructions on how to set up the agent.\n",
        "\n",
        "### Step 1: Access Flotorch Console\n",
        "\n",
        "1. **Log in to Flotorch Console**:\n",
        "   - Navigate to your Flotorch Console (e.g., `https://dev-console.flotorch.cloud`)\n",
        "   - Ensure you have the necessary permissions to create agents\n",
        "\n",
        "2. **Navigate to Agents Section**:\n",
        "   - Click on **\"Agents\"** in the left sidebar\n",
        "   - You should see the \"Agent Builder\" option selected\n",
        "\n",
        "### Step 2: Create New Agent\n",
        "\n",
        "1. **Click \"Create FloTorch Agent\"**:\n",
        "   - Look for the blue **\"+ Create FloTorch Agent\"** button in the top right corner\n",
        "   - Click it to start creating a new agent\n",
        "\n",
        "2. **Agent Configuration**:\n",
        "   - **Agent Name**: Choose a unique name for your agent (e.g., `news-summary-agent`)\n",
        "     - **Important**: The name should only contain alphanumeric characters and dashes (a-z, A-Z, 0-9, -)\n",
        "     - **Note**: Copy this agent name - you'll need to use it in the `agent_name` variable later\n",
        "   - **Description** (Optional): Add a description if desired\n",
        "\n",
        "### Step 3: Configure Agent Details\n",
        "\n",
        "After creating the agent, you'll be directed to the agent configuration page. Configure the following:\n",
        "\n",
        "#### Required Configuration:\n",
        "\n",
        "1. **Model** (`* Model`):\n",
        "   - **Required**: Select a model from the available options\n",
        "   - Example: `gpt-model` or any available model from your Flotorch gateway\n",
        "   - Click the edit icon to configure\n",
        "\n",
        "2. **Agent Details** (`* Agent Details`):\n",
        "   - **Required**: Configure agent details\n",
        "   - **System Prompt**: Copy and paste the following system prompt:\n",
        "\n",
        "you are the helpful assistant. you need to call get_top_news tool when the new about the news you need give top 7  current news from the world wide  mainly from the India.\n",
        "\n",
        "Available Tools:\n",
        "get_top_news\n",
        "\n",
        "\n",
        "\n",
        "   - **Goal**: Copy and paste the following goal:\n",
        "   \n",
        "you are the helpful assistant. you need to call get_top_news tool when the new about the news you need give top 7  current news from the world wide  mainly from the India.\n",
        "\n",
        "#### Optional Configuration:\n",
        "\n",
        "1. **Tools**:\n",
        "   - Tools will be added programmatically via the notebook (see Section 8)\n",
        "   - You can leave this as \"Not Configured\" in the console\n",
        "\n",
        "2. **Input Schema**:\n",
        "   - Optional: Leave as \"Not Configured\" for this use case\n",
        "\n",
        "3. **Output Schema**:\n",
        "   - Optional: Leave as \"Not Configured\" for this use case\n",
        "\n",
        "### Step 4: Publish the Agent\n",
        "\n",
        "1. **Review Configuration**:\n",
        "   - Ensure the Model and Agent Details are configured correctly\n",
        "   - Verify the System Prompt and Goal are set\n",
        "\n",
        "2. **Publish Agent**:\n",
        "   - After configuration, click **\"Publish\"** or **\"Make a revision\"** to publish the agent\n",
        "   - Once published, the agent will have a version number (e.g., v1)\n",
        "\n",
        "3. **Note the Agent Name**:\n",
        "   - **Important**: Copy the exact agent name you used when creating the agent\n",
        "   - You will need to replace `<your_agent_name>` in the `agent_name` variable in Section 2.1 (Global Provider Models and Agent Configuration)\n",
        "\n",
        "### Step 5: Update Notebook Configuration\n",
        "\n",
        "1. **Update Agent Name**:\n",
        "   - Navigate to Section 2.1 in this notebook\n",
        "   - Find the `agent_name` variable\n",
        "   - Replace `<your_agent_name>` with the exact agent name you created in the console\n",
        "\n",
        "**Example**:\n",
        "- If you created an agent named `news-summary-agent` in the console\n",
        "- Set `agent_name = \"news-summary-agent\"` in the notebook\n",
        "\n",
        "### Summary of Required vs Optional Settings\n",
        "\n",
        "| Setting | Required/Optional | Value |\n",
        "|---------|------------------|-------|\n",
        "| **Agent Name** | **Required** | Choose a unique name (copy it for notebook) |\n",
        "| **Model** | **Required** | Select from available models |\n",
        "| **System Prompt** | **Required** | Use the system prompt provided above |\n",
        "| **Goal** | **Required** | Use the goal provided above |\n",
        "| **Tools** | **Optional** | Will be added via notebook code |\n",
        "| **Input Schema** | **Optional** | Can leave as \"Not Configured\" |\n",
        "| **Output Schema** | **Optional** | Can leave as \"Not Configured\" |\n",
        "\n",
        "**Note**: The tools (Knowledge Base, Web Search, Weather, News) will be added to the agent programmatically in the notebook code, so you don't need to configure them manually in the console.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d3f6795",
      "metadata": {
        "id": "7d3f6795"
      },
      "source": [
        "## 1. Setup and Installation\n",
        "\n",
        "### Purpose\n",
        "Install the necessary packages for the Flotorch Evaluation framework required for usage and cost metric evaluation.\n",
        "\n",
        "### Key Components\n",
        "- **`flotorch-eval`**: Flotorch evaluation framework with all dependencies for usage metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z9dJX-WsV3aD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9dJX-WsV3aD",
        "outputId": "540a5206-2313-4d96-a5a1-1cfde636b107"
      },
      "outputs": [],
      "source": [
        "# Install Flotorch Eval packages\n",
        "# flotorch-eval: Flotorch evaluation framework with all dependencies\n",
        "\n",
        "%pip install flotorch-eval==2.0.0b1 flotorch[adk]==3.1.0b1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87732d23",
      "metadata": {
        "id": "87732d23"
      },
      "source": [
        "## 2.Authentication and Credentials\n",
        "\n",
        "### Purpose\n",
        "Configure your Flotorch API credentials and gateway URL for authentication.\n",
        "\n",
        "### Key Components\n",
        "This cell configures the essential authentication and connection parameters:\n",
        "\n",
        "**Authentication Parameters**:\n",
        "\n",
        "| Parameter | Description | Example |\n",
        "|-----------|-------------|---------|\n",
        "| `FLOTORCH_API_KEY` | Your API authentication key (found in your Flotorch Console). Securely entered using `getpass` to avoid displaying in the notebook | `sk_...` |\n",
        "| `FLOTORCH_BASE_URL` | Your Flotorch gateway endpoint URL | `https://dev-console.flotorch.cloud` |\n",
        "\n",
        "**Note**: Use secure credential management in production environments.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "637a97a5",
      "metadata": {
        "id": "637a97a5"
      },
      "outputs": [],
      "source": [
        "import getpass  # Securely prompt without echoing in Prefect/notebooks\n",
        "\n",
        "# authentication for Flotorch access\n",
        "try:\n",
        "    FLOTORCH_API_KEY = getpass.getpass(\"Paste your API key here: \")  \n",
        "    print(f\"✓ FLOTORCH_API_KEY set successfully\")\n",
        "except getpass.GetPassWarning as e:\n",
        "    print(f\"Warning: {e}\")\n",
        "    FLOTORCH_API_KEY = \"\"\n",
        "    print(f\"✗ FLOTORCH_API_KEY not set\")\n",
        "\n",
        "FLOTORCH_BASE_URL = input(\"Paste your Flotorch Base URL here: \")  # Prefect gateway or cloud endpoint          || https://dev-console.flotorch.cloud\n",
        "print(f\"✓ FLOTORCH_BASE_URL set: {FLOTORCH_BASE_URL}\")\n",
        "\n",
        "print(\"✓ All credentials configured successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56dd94ce",
      "metadata": {
        "id": "56dd94ce"
      },
      "source": [
        "### 2.1. Global Provider Models and Agent Configuration\n",
        "\n",
        "### Purpose\n",
        "Define available models from the Flotorch gateway and configure agent-specific parameters.\n",
        "\n",
        "### Key Components\n",
        "\n",
        "**Global Provider Models**: These are the available models from the Flotorch gateway that can be used for evaluation and agent operations:\n",
        "\n",
        "| Model Variable | Model Name | Description |\n",
        "|----------------|------------|-------------|\n",
        "| `MODEL_CLAUDE_HAIKU` | `flotorch/flotorch-claude-haiku-4-5` | Claude Haiku model via Flotorch gateway |\n",
        "| `MODEL_CLAUDE_SONNET` | `flotorch/flotorch-claude-sonnet-3-5-v2` | Claude Sonnet model via Flotorch gateway |\n",
        "| `MODEL_AWS_NOVA_PRO` | `flotorch/flotorch-aws-nova-pro` | AWS Nova Pro model via Flotorch gateway |\n",
        "| `MODEL_AWS_NOVA_LITE` | `flotorch/flotorch-aws-nova-lite` | AWS Nova Lite model via Flotorch gateway |\n",
        "| `MODEL_AWS_NOVA_MICRO` | `flotorch/flotorch-aws-nova-micro` | AWS Nova Micro model via Flotorch gateway |\n",
        "\n",
        "**Agent Configuration Parameters**:\n",
        "\n",
        "| Parameter | Description | Example |\n",
        "|-----------|-------------|---------|\n",
        "| `default_evaluator` | The LLM model used for evaluation (can use MODEL_* variables above) | `MODEL_CLAUDE_SONNET` or `flotorch/flotorch-model` |\n",
        "| `agent_name` | The name of your Flotorch ADK agent | `news-summary-agent` |\n",
        "| `app_name` | The application name identifier | `agent-evaluation-app-name_06` |\n",
        "| `user_id` | The user identifier | `agent-evaliation-user-06` |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fed21d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fed21d5",
        "outputId": "d1bcacd0-b2e6-4a89-8e1a-41706bba2cb1"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Global Provider Models (Flotorch Gateway Models)\n",
        "# ============================================================================\n",
        "# These models are available from the Flotorch gateway and can be used\n",
        "# for evaluation, agent operations, and other tasks.\n",
        "\n",
        "MODEL_CLAUDE_HAIKU = \"flotorch/flotorch-claude-haiku-4-5\"\n",
        "MODEL_CLAUDE_SONNET = \"flotorch/flotorch-claude-sonnet-3-5-v2\"\n",
        "MODEL_AWS_NOVA_PRO = \"flotorch/flotorch-aws-nova-pro\"\n",
        "MODEL_AWS_NOVA_LITE = \"flotorch/flotorch-aws-nova-lite\"\n",
        "MODEL_AWS_NOVA_MICRO = \"flotorch/flotorch-aws-nova-micro\"\n",
        "\n",
        "print(\"✓ Global provider models defined\")\n",
        "\n",
        "# The LLM model used for evaluation.\n",
        "# Can be modified to use any MODEL_* constant above (e.g., MODEL_CLAUDE_SONNET, MODEL_AWS_NOVA_PRO)\n",
        "# You can use your own models from Flotorch Console as well\n",
        "default_evaluator = \"<your_default_evaluator>\"                                                                 # ex : flotorch/gpt-4o-model\n",
        "\n",
        "agent_name = \"<your_agent_name>\"  # The name of your Flotorch ADK agent                                        || ex : news-summary-agent\n",
        "app_name = \"<your_app_name>\"  # The application name identifier                                                || ex : agent-evaluation-app-name_06\n",
        "user_id = \"<your_user_id>\"  # The user identifier                                                              || ex : agent-evaliation-user-06\n",
        "\n",
        "print(\"✓ Agent Configuration Parameter defined \")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99963dc0",
      "metadata": {
        "id": "99963dc0"
      },
      "source": [
        "## 3. Import Required Libraries\n",
        "\n",
        "### Purpose\n",
        "Import all required components for evaluating the News Summary Agent usage metrics using Flotorch Eval.\n",
        "\n",
        "### Key Components\n",
        "- **`AgentEvaluator`**: Core client for agent evaluation orchestration and trace fetching\n",
        "- **`UsageMetric`**: Flotorch Eval metric that evaluates usage and cost data\n",
        "- **`FlotorchADKAgent`**: Creates and configures Flotorch ADK agents with custom tools and tracing\n",
        "- **`FlotorchADKSession`**: Manages agent sessions for multi-turn conversations\n",
        "- **`Runner`**: Executes agent queries and coordinates the agent execution flow\n",
        "- **`FunctionTool`**: Wraps Python functions as tools that can be used by the agent\n",
        "- **`types`**: Google ADK types for creating message content and handling agent events\n",
        "- **`pandas`**: Data manipulation and display for formatted results tables\n",
        "- **`display`**: IPython display utility for rendering formatted outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d5345ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d5345ba",
        "outputId": "23dbcc4a-d5ce-4a28-b682-d33c1cbfaa4d"
      },
      "outputs": [],
      "source": [
        "# Required imports\n",
        "# Flotorch Eval components\n",
        "from flotorch_eval.agent_eval.core.client import AgentEvaluator\n",
        "from flotorch_eval.agent_eval.metrics.usage_metrics import UsageMetric\n",
        "\n",
        "# Flotorch ADK components\n",
        "from flotorch.adk.agent import FlotorchADKAgent\n",
        "from flotorch.adk.sessions import FlotorchADKSession\n",
        "\n",
        "# Google ADK components\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.tools import FunctionTool\n",
        "from google.genai import types\n",
        "\n",
        "# Utilities\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "print(\"✓ Imported necessary libraries successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33d236c2",
      "metadata": {
        "id": "33d236c2"
      },
      "source": [
        "## 4. News Summary Agent Setup\n",
        "\n",
        "### Purpose\n",
        "Set up the News Summary Agent with OpenTelemetry tracing enabled to capture detailed execution data for usage and cost metric evaluation.\n",
        "\n",
        "### Key Components\n",
        "1. **FlotorchADKAgent** (`agent_client`):\n",
        "   - Initializes the agent for news fetching and summarization tasks\n",
        "   - Configures `tracer_config` with `enabled: True` and `sampling_rate: 1` to capture 100% of traces\n",
        "   - Essential for evaluation as traces contain complete usage and cost information\n",
        "2. **FlotorchADKSession** (`session_service`): Manages agent sessions for multi-turn conversations\n",
        "3. **Runner** (`runner`): Executes agent queries and coordinates the agent execution flow\n",
        "\n",
        "These components work together to run the News Summary Agent and generate OpenTelemetry traces for usage and cost analysis.\n",
        "\n",
        "### Custom Tool: News Fetching\n",
        "\n",
        "The News Summary Agent uses a custom tool (`get_top_news`) that integrates with RSS feeds to retrieve the latest news articles. This tool:\n",
        "- Accepts a limit parameter to specify the maximum number of articles to return\n",
        "- Uses Google News RSS feeds to fetch the latest news articles from worldwide sources, with priority on India\n",
        "- Parses RSS feeds and extracts structured information including titles, descriptions, links, and publication dates\n",
        "- Returns structured news information with article details\n",
        "- Handles errors gracefully with exception handling\n",
        "\n",
        "The tool is wrapped as a `FunctionTool` that can be used by the agent to deliver real-time news summaries via RSS feed integration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "882c2118",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "882c2118",
        "outputId": "7412749c-c5c8-4be2-a6e4-80230cc7399a"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from typing import Dict, Any\n",
        "from datetime import datetime\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def get_top_news(limit: int = 7) -> Dict[str, Any]:\n",
        "    \"\"\"Get the latest top news articles from worldwide, with priority on India.\n",
        "    Fetches and summarizes the latest news using news APIs (e.g., NewsAPI).\n",
        "    Returns today's latest news articles from major sources. No API key needed.\n",
        "\n",
        "    Args:\n",
        "        limit: The maximum number of articles to return (default: 7)\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing news articles with titles, descriptions, and links\n",
        "    \"\"\"\n",
        "    try:\n",
        "        articles = []\n",
        "        headers = {\n",
        "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "        }\n",
        "\n",
        "        # Helper function to parse RSS feed and extract articles\n",
        "        def parse_rss_feed(url: str, max_items: int) -> list:\n",
        "            parsed_articles = []\n",
        "            try:\n",
        "                response = requests.get(url, timeout=10, headers=headers)\n",
        "                if response.status_code == 200:\n",
        "                    root = ET.fromstring(response.content)\n",
        "                    for item in root.findall('.//item'):\n",
        "                        if len(parsed_articles) >= max_items:\n",
        "                            break\n",
        "                        title_elem = item.find('title')\n",
        "                        link_elem = item.find('link')\n",
        "                        pub_date_elem = item.find('pubDate')\n",
        "                        desc_elem = item.find('description')\n",
        "\n",
        "                        title = title_elem.text if title_elem is not None else \"No title\"\n",
        "                        # Clean title (remove source prefixes like \"BBC News - \")\n",
        "                        if \" - \" in title:\n",
        "                            title = title.split(\" - \", 1)[-1]\n",
        "\n",
        "                        # Skip duplicates\n",
        "                        if not any(a[\"title\"] == title for a in articles + parsed_articles):\n",
        "                            parsed_articles.append({\n",
        "                                \"title\": title,\n",
        "                                \"description\": desc_elem.text if desc_elem is not None else \"\",\n",
        "                                \"url\": link_elem.text if link_elem is not None else \"\",\n",
        "                                \"publishedAt\": pub_date_elem.text if pub_date_elem is not None else str(datetime.now()),\n",
        "                                \"source\": {\"name\": \"Google News\"}\n",
        "                            })\n",
        "            except Exception:\n",
        "                pass\n",
        "            return parsed_articles\n",
        "\n",
        "        # Priority 1: Get India news (today's latest) - try multiple sources\n",
        "        india_news_urls = [\n",
        "            \"https://news.google.com/rss/search?q=india+when:1d&hl=en-IN&gl=IN&ceid=IN:en\",\n",
        "            \"https://news.google.com/rss/headlines/section/topic/WORLD?hl=en-IN&gl=IN&ceid=IN:en\",\n",
        "            \"https://news.google.com/rss/search?q=India+latest+news+today&hl=en-IN&gl=IN&ceid=IN:en\"\n",
        "        ]\n",
        "\n",
        "        for url in india_news_urls:\n",
        "            if len(articles) >= limit:\n",
        "                break\n",
        "            new_articles = parse_rss_feed(url, limit - len(articles))\n",
        "            articles.extend(new_articles)\n",
        "\n",
        "        # Priority 2: Fill with worldwide news if needed\n",
        "        if len(articles) < limit:\n",
        "            world_news_urls = [\n",
        "                \"https://news.google.com/rss/search?q=world+news+when:1d&hl=en&gl=US&ceid=US:en\",\n",
        "                \"https://news.google.com/rss/headlines/section/topic/WORLD?hl=en&gl=US&ceid=US:en\"\n",
        "            ]\n",
        "\n",
        "            for url in world_news_urls:\n",
        "                if len(articles) >= limit:\n",
        "                    break\n",
        "                new_articles = parse_rss_feed(url, limit - len(articles))\n",
        "                articles.extend(new_articles)\n",
        "\n",
        "        # Limit to requested number\n",
        "        articles = articles[:limit]\n",
        "\n",
        "        return {\n",
        "            \"status\": \"success\",\n",
        "            \"totalResults\": len(articles),\n",
        "            \"articles\": articles,\n",
        "            \"fetchedAt\": str(datetime.now())\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"status\": \"error\",\n",
        "            \"message\": f\"Failed to fetch news: {str(e)}\",\n",
        "            \"articles\": []\n",
        "        }\n",
        "\n",
        "# --- Wrap as ADK Tool ---\n",
        "tools = [FunctionTool(get_top_news)]\n",
        "\n",
        "print(\"✓ News fetching tool defined and registered successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c42916b",
      "metadata": {
        "id": "6c42916b"
      },
      "source": [
        "## 5. Agent and Runner Initialization\n",
        "\n",
        "### Purpose\n",
        "Set up the Flotorch ADK Agent and Runner with OpenTelemetry tracing enabled to capture detailed execution data for usage and cost metric evaluation.\n",
        "\n",
        "### Key Components\n",
        "1. **FlotorchADKAgent** (`agent_client`):\n",
        "   - Initializes the agent with custom news fetching tools\n",
        "   - Configures `tracer_config` with `enabled: True` and `sampling_rate: 1` to capture 100% of traces\n",
        "   - Essential for evaluation as traces contain complete usage and cost information\n",
        "2. **FlotorchADKSession** (`session_service`): Manages agent sessions for multi-turn conversations\n",
        "3. **Runner** (`runner`): Executes agent queries and coordinates the agent execution flow\n",
        "\n",
        "These components work together to run the News Summary Agent and generate OpenTelemetry traces for usage and cost analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4ea47ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4ea47ea",
        "outputId": "9183dc4b-4d6d-47e1-a25a-4187e1d3d17d"
      },
      "outputs": [],
      "source": [
        "# Initialize Flotorch ADK Agent with tracing enabled\n",
        "agent_client = FlotorchADKAgent(\n",
        "    agent_name=agent_name,\n",
        "    custom_tools=tools,\n",
        "    base_url=FLOTORCH_BASE_URL,\n",
        "    api_key=FLOTORCH_API_KEY,\n",
        "    tracer_config={\n",
        "        \"enabled\": True,                                                   # Enable tracing for Usage measurement\n",
        "        \"endpoint\": \"https://dev-observability.flotorch.cloud/v1/traces\",  # Dev observability OTLP HTTP endpoint (used by QA)\n",
        "        \"sampling_rate\": 1                                                 # Sample 100% of traces\n",
        "    }\n",
        ")\n",
        "agent = agent_client.get_agent()\n",
        "\n",
        "# Initialize session service\n",
        "session_service = FlotorchADKSession(\n",
        "    api_key=FLOTORCH_API_KEY,\n",
        "    base_url=FLOTORCH_BASE_URL,\n",
        ")\n",
        "\n",
        "# Create the ADK Runner to execute agent queries\n",
        "runner = Runner(\n",
        "    agent=agent,\n",
        "    app_name=app_name,\n",
        "    session_service=session_service\n",
        ")\n",
        "\n",
        "print(\"✓ Agent and runner and session initialized successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c89d7795",
      "metadata": {
        "id": "c89d7795"
      },
      "source": [
        "## 6. Helper Function for Running a Query\n",
        "\n",
        "### Purpose\n",
        "Define a helper function that executes a single-turn query with the agent and extracts the final response. The agent execution is automatically traced for usage and cost metric evaluation.\n",
        "\n",
        "### Functionality\n",
        "The `run_single_turn` function:\n",
        "- Accepts a `Runner`, query string, session ID, and user ID as parameters\n",
        "- Creates a user message using Google ADK types\n",
        "- Executes the query through the runner\n",
        "- Iterates through events to find and return the final agent response\n",
        "- Returns a fallback message if no response is found\n",
        "\n",
        "This function simplifies the process of running queries and ensures trace generation during execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b51ef384",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b51ef384",
        "outputId": "eb4d50ad-7c76-4dda-f450-3baa4494f1f7"
      },
      "outputs": [],
      "source": [
        "def run_single_turn(runner: Runner, query: str, session_id: str, user_id: str) -> str:\n",
        "    \"\"\"\n",
        "    Execute a single-turn query with the agent and return the final response.\n",
        "    The agent execution is traced automatically.\n",
        "    \"\"\"\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
        "    events = runner.run(user_id=user_id, session_id=session_id, new_message=content)\n",
        "\n",
        "    # Extract the final response\n",
        "    for event in events:\n",
        "        if event.is_final_response() and event.content and event.content.parts:\n",
        "            return event.content.parts[0].text\n",
        "    return \"No response from agent.\"\n",
        "\n",
        "print(\"✓ Helper function defined successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "577c21cf",
      "metadata": {
        "id": "577c21cf"
      },
      "source": [
        "## 7. Define Query\n",
        "\n",
        "### Purpose\n",
        "Define the sample news query that will be executed by the News Summary Agent to generate OpenTelemetry traces for usage and cost metric evaluation.\n",
        "\n",
        "### Key Components\n",
        "- **`query`**: A sample news request that will be processed by the agent\n",
        "  - This query will trigger the agent to fetch and summarize news articles using news API tools\n",
        "  - The query will test the agent's ability to retrieve and process multiple news articles\n",
        "  - The execution will be automatically traced to capture token usage and cost information\n",
        "  - The usage data (tokens, costs) will be evaluated using the UsageMetric to compute usage_summary metrics\n",
        "  - Example: \"Get me the top 7 latest news articles from around the world, especially from India\"\n",
        "\n",
        "The query can be modified to test different news scenarios and evaluate usage and cost metrics for various types of news-related requests.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61e7b243",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61e7b243",
        "outputId": "9d19f517-0626-4101-d39a-094d2ef647c0"
      },
      "outputs": [],
      "source": [
        "# Execute the query to generate traces\n",
        "\n",
        "query = \"Get me the top 7 latest news articles from around the world, especially from India\"\n",
        "\n",
        "print(f\"Query defined : {query}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5742fdf",
      "metadata": {
        "id": "c5742fdf"
      },
      "source": [
        "## 7. Run the Query and Get Trace ID\n",
        "\n",
        "### Purpose\n",
        "Execute a sample news query with the News Summary Agent to generate OpenTelemetry traces that contain usage and cost data for evaluation.\n",
        "\n",
        "### Process\n",
        "1. **Create Session**: Initialize a new session for the agent interaction\n",
        "2. **Execute Query**: Run a sample news query (e.g., \"Get me the top 7 latest news articles from around the world, especially from India\") through the agent\n",
        "3. **Retrieve Trace IDs**: Extract the generated trace IDs from the agent client\n",
        "4. **Display Results**: Print the agent response and trace ID for verification\n",
        "\n",
        "The execution automatically generates OpenTelemetry traces that record usage and cost information, which will be used for usage metric evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f98ad20c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f98ad20c",
        "outputId": "f0ad43c7-62e7-4287-b290-c78f41f1a53b"
      },
      "outputs": [],
      "source": [
        "# Create a new session\n",
        "session = await runner.session_service.create_session(\n",
        "    app_name=app_name,\n",
        "    user_id=user_id,\n",
        ")\n",
        "print(f\"Session created: {session.id}\")\n",
        "\n",
        "response = run_single_turn(\n",
        "    runner=runner,\n",
        "    query=query,\n",
        "    session_id=session.id,\n",
        "    user_id=user_id\n",
        ")\n",
        "\n",
        "# Retrieve the generated trace IDs\n",
        "trace_ids = agent_client.get_tracer_ids()\n",
        "print(trace_ids)\n",
        "print(\"Agent Response:\")\n",
        "print(response[:200] + \"...\" if len(response) > 200 else response)\n",
        "print(f\"Found {len(trace_ids)} trace(s). First trace ID: {trace_ids[0] if trace_ids else 'N/A'}\")\n",
        "\n",
        "print(f\"✓ Query execution completed successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GW3N-qrF3mM_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW3N-qrF3mM_",
        "outputId": "27675032-5dcd-4504-cf9a-7ae9ec45e073"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# PATCH: Fix for model name lookup in pricing data (Colab compatibility)\n",
        "# ============================================================================\n",
        "# This patch handles cases where model names in traces (e.g., 'gpt-4o-2024-08-06')\n",
        "# don't match the exact format in the pricing API (e.g., 'gpt-4o').\n",
        "\n",
        "from flotorch_eval.common.cost_compute_utils import PriceCache\n",
        "\n",
        "def normalize_model_name(model_id: str) -> list:\n",
        "    \"\"\"Generate possible model name variations for lookup.\"\"\"\n",
        "    variations = [model_id]  # Try original first\n",
        "\n",
        "    # Remove date suffixes (e.g., 'gpt-4o-2024-08-06' -> 'gpt-4o')\n",
        "    if '-' in model_id:\n",
        "        parts = model_id.split('-')\n",
        "        # Check if last 3 parts form a date (YYYY-MM-DD format)\n",
        "        if len(parts) >= 4:\n",
        "            try:\n",
        "                if (len(parts[-3]) == 4 and parts[-3].isdigit() and\n",
        "                    len(parts[-2]) == 2 and parts[-2].isdigit() and\n",
        "                    len(parts[-1]) == 2 and parts[-1].isdigit()):\n",
        "                    base_name = '-'.join(parts[:-3])\n",
        "                    if base_name not in variations:\n",
        "                        variations.append(base_name)\n",
        "            except (ValueError, IndexError):\n",
        "                pass\n",
        "\n",
        "        # Also try removing just the last segment\n",
        "        if len(parts) > 1:\n",
        "            base_name = '-'.join(parts[:-1])\n",
        "            if base_name not in variations:\n",
        "                variations.append(base_name)\n",
        "\n",
        "    # Handle flotorch/ prefix\n",
        "    if model_id.startswith('flotorch/'):\n",
        "        without_prefix = model_id.replace('flotorch/', '')\n",
        "        if without_prefix not in variations:\n",
        "            variations.append(without_prefix)\n",
        "\n",
        "    return variations\n",
        "\n",
        "# Patch the PriceCache.get_model_cost method\n",
        "original_get_model_cost = PriceCache.get_model_cost\n",
        "\n",
        "async def patched_get_model_cost(self, model_id: str, force_refresh=False):\n",
        "    \"\"\"\n",
        "    Patched version that tries multiple model name variations.\n",
        "    \"\"\"\n",
        "    # Call get_price_list on the instance - this should work correctly\n",
        "    price_list = await self.get_price_list(force_refresh=force_refresh)\n",
        "\n",
        "    # Try original model_id first\n",
        "    if model_id in price_list:\n",
        "        return price_list[model_id][\"cost\"]\n",
        "\n",
        "    # Try normalized variations\n",
        "    variations = normalize_model_name(model_id)\n",
        "    for variation in variations[1:]:  # Skip first since we already tried it\n",
        "        if variation in price_list:\n",
        "            return price_list[variation][\"cost\"]\n",
        "\n",
        "    # If still not found, try force refresh to get latest pricing data\n",
        "    if not force_refresh:\n",
        "        try:\n",
        "            price_list = await self.get_price_list(force_refresh=True)\n",
        "            if model_id in price_list:\n",
        "                return price_list[model_id][\"cost\"]\n",
        "\n",
        "            # Try variations again with fresh data\n",
        "            for variation in variations[1:]:\n",
        "                if variation in price_list:\n",
        "                    return price_list[variation][\"cost\"]\n",
        "        except Exception:\n",
        "            pass  # If refresh fails, continue to error\n",
        "\n",
        "    # Generate helpful error message\n",
        "    available_models = list(price_list.keys())[:10]  # Show first 10 as examples\n",
        "    error_msg = (\n",
        "        f\"Model '{model_id}' not found in pricing data.\\n\"\n",
        "        f\"Tried variations: {', '.join(variations)}\\n\"\n",
        "        f\"Available models (sample): {', '.join(available_models)}...\\n\"\n",
        "        f\"Total models in pricing data: {len(price_list)}\\n\"\n",
        "        f\"Tip: The pricing data may need to be refreshed or the model name format may differ.\"\n",
        "    )\n",
        "    raise ValueError(error_msg)\n",
        "\n",
        "# Apply the patch - assign directly to class, Python will bind it correctly\n",
        "PriceCache.get_model_cost = patched_get_model_cost\n",
        "\n",
        "print(\"✓ Model name lookup patch applied successfully (Colab compatibility fix)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00df1d34",
      "metadata": {
        "id": "00df1d34"
      },
      "source": [
        "## 9. Usage Metric Evaluation with Flotorch Eval\n",
        "\n",
        "### Purpose\n",
        "Initialize the `AgentEvaluator`, fetch the OpenTelemetry trace, and run the `UsageMetric` to evaluate usage and cost metrics. The evaluation metric **usage_summary** provides detailed assessment of token usage and costs for the News Summary Agent.\n",
        "\n",
        "### Key Components\n",
        "1. **UsageMetric**: Initializes the usage metric that will analyze trace data\n",
        "2. **AgentEvaluator** (`client`):\n",
        "   - Connects to the Flotorch gateway using API credentials\n",
        "   - Configured with a default evaluator model\n",
        "   - Provides methods to fetch and evaluate traces\n",
        "3. **Trace Fetching**: Retrieves the complete trace data using the trace ID generated during agent execution\n",
        "\n",
        "The fetched trace contains detailed information about token usage and costs, which will be analyzed by the UsageMetric to compute the usage_summary score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K87V-Smi2X6H",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K87V-Smi2X6H",
        "outputId": "67eaf77c-028d-41d9-db8d-1b97c9864293"
      },
      "outputs": [],
      "source": [
        "def display_metrics(result):\n",
        "    \"\"\"\n",
        "    Display usage summary metrics in a formatted table.\n",
        "    \"\"\"\n",
        "    # Find the usage_summary metric\n",
        "    metric = next((m for m in result.scores if m.name == \"usage_summary\"), None)\n",
        "    if not metric:\n",
        "        print(\"No usage_summary metric found.\")\n",
        "        return\n",
        "\n",
        "    # Extract metric details\n",
        "    d = metric.details\n",
        "\n",
        "    # Get cost information\n",
        "    total_cost = d.get(\"total_cost\", \"0.000000\")\n",
        "    avg_cost_per_call = d.get(\"average_cost_per_call\", \"0.000000\")\n",
        "    cost_breakdown = d.get(\"cost_breakdown\", [])\n",
        "\n",
        "    # Format cost breakdown\n",
        "    if cost_breakdown:\n",
        "        breakdown_lines = []\n",
        "        for item in cost_breakdown:\n",
        "            if isinstance(item, dict):\n",
        "                # Format each cost item\n",
        "                item_str = f\"    - {item.get('operation', 'Unknown')}: ${item.get('cost', '0.000000')}\"\n",
        "                if 'count' in item:\n",
        "                    item_str += f\" ({item['count']} calls)\"\n",
        "                breakdown_lines.append(item_str)\n",
        "            else:\n",
        "                breakdown_lines.append(f\"    - {item}\")\n",
        "        breakdown_text = \"\\n\".join(breakdown_lines)\n",
        "    else:\n",
        "        breakdown_text = \"    No cost breakdown available.\"\n",
        "\n",
        "    # Format the details string\n",
        "    details = (\n",
        "        f\"Total Cost: ${total_cost}\\n\"\n",
        "        f\"Average Cost per Call: ${avg_cost_per_call}\\n\"\n",
        "        f\"\\nCost Breakdown:\\n{breakdown_text}\"\n",
        "    )\n",
        "\n",
        "    # Create DataFrame for display\n",
        "    df = pd.DataFrame([{\n",
        "        \"Metric\": metric.name.replace(\"_\", \" \").title(),\n",
        "        \"Score\": f\"${total_cost}\",\n",
        "        \"Details\": details\n",
        "    }])\n",
        "\n",
        "    # Display DataFrame with multiline support\n",
        "    display(df.style.set_properties(\n",
        "        subset=['Details'],\n",
        "        **{'white-space': 'pre-wrap', 'text-align': 'left'}\n",
        "    ))\n",
        "\n",
        "print(\"✓ Display metrics function defined successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0c963e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0c963e4",
        "outputId": "33095a8a-c98a-438c-9a9a-de9920696814"
      },
      "outputs": [],
      "source": [
        "# Initialize the UsageMetric\n",
        "metrics = [UsageMetric()]\n",
        "\n",
        "# Initialize the AgentEvaluator client\n",
        "client = AgentEvaluator(\n",
        "    api_key=FLOTORCH_API_KEY,\n",
        "    base_url=FLOTORCH_BASE_URL,\n",
        "    default_evaluator=default_evaluator\n",
        ")\n",
        "\n",
        "traces = None\n",
        "if trace_ids:\n",
        "    # Fetch the trace data from the Flotorch gateway\n",
        "    traces = client.fetch_traces(trace_ids[0])\n",
        "    print(f\"✓ Trace fetched successfully\")\n",
        "else:\n",
        "    print(\"✗ No trace IDs found to fetch.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "218e8814",
      "metadata": {
        "id": "218e8814"
      },
      "source": [
        "## 10. Run Evaluation\n",
        "\n",
        "### Purpose\n",
        "Execute the usage metric evaluation by processing the fetched OpenTelemetry trace using the UsageMetric to assess token usage and costs.\n",
        "\n",
        "### Process\n",
        "- Calls `client.evaluate()` with the trace data and UsageMetric\n",
        "- The evaluator processes the trace to analyze usage and cost data\n",
        "- Computes the **usage_summary** metric which includes:\n",
        "  - Total cost for all agent operations\n",
        "  - Average cost per call\n",
        "  - Cost breakdown for individual operations:\n",
        "    - LLM calls with token usage (input/output tokens) and associated costs\n",
        "    - Tool execution costs (if applicable)\n",
        "    - Per-operation cost breakdown\n",
        "- Returns evaluation results with trajectory ID and metric scores\n",
        "\n",
        "This step generates the usage and cost analysis that will be displayed in the next section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d832fc0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d832fc0",
        "outputId": "dd18b47d-0bde-452e-cfdd-62de8b12222a"
      },
      "outputs": [],
      "source": [
        "if 'traces' in locals() and traces:\n",
        "    # Evaluate the trace using the UsageMetric\n",
        "    results = await client.evaluate(\n",
        "        trace=traces,\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    print(\"✓ Evaluation completed successfully!\")\n",
        "else:\n",
        "    print(\"Cannot evaluate: No traces were available.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35e8da4c",
      "metadata": {
        "id": "35e8da4c"
      },
      "source": [
        "## 11. Display and Interpret Results\n",
        "\n",
        "### Purpose\n",
        "Define helper functions to format and display the evaluation output clearly, showing the usage_summary metric results in a readable format.\n",
        "\n",
        "### Functionality\n",
        "The `display_metrics` function:\n",
        "- Extracts the `usage_summary` metric from evaluation results\n",
        "- Formats the cost information and usage details\n",
        "- Creates a structured display showing:\n",
        "  - Total Cost\n",
        "  - Average Cost per Call\n",
        "  - Cost breakdown for individual operations with token counts\n",
        "- Uses pandas DataFrame with styled formatting for clean presentation\n",
        "\n",
        "This function provides a user-friendly way to visualize usage and cost metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c436137c",
      "metadata": {
        "id": "c436137c"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "27de8dc3",
      "metadata": {
        "id": "27de8dc3"
      },
      "source": [
        "## 12. View Usage Summary Results\n",
        "\n",
        "### Purpose\n",
        "Display the usage summary evaluation results in a formatted table showing the complete cost and usage assessment for the News Summary Agent.\n",
        "\n",
        "### Output\n",
        "The displayed table includes:\n",
        "- **Metric**: The evaluation metric name (usage_summary)\n",
        "- **Score**: The total cost in USD\n",
        "- **Details**: Comprehensive usage and cost breakdown showing:\n",
        "  - Total Cost\n",
        "  - Average Cost per Call\n",
        "  - Cost breakdown for individual operations:\n",
        "    - LLM calls with token counts\n",
        "    - Tool executions\n",
        "    - Per-operation cost analysis\n",
        "\n",
        "This visualization helps identify expensive operations and optimize the agent's cost efficiency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d055ba70",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "id": "d055ba70",
        "outputId": "c3b34bf6-852c-43f6-ce4d-e07a3cecd259"
      },
      "outputs": [],
      "source": [
        "if 'results' in locals():\n",
        "    display_metrics(results)\n",
        "else:\n",
        "    print(\"No results object found. Please run sections 5 and 6 first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0401dec6",
      "metadata": {
        "id": "0401dec6"
      },
      "source": [
        "### Interpreting the Usage Summary\n",
        "\n",
        "The **usage_summary** metric is a vital tool for cost monitoring and optimization of the News Summary Agent:\n",
        "\n",
        "* **Total Cost**: The cumulative cost for all agent operations, including LLM calls and tool executions. This provides an overall view of operational expenses.\n",
        "* **Average Cost per Call**: The mean cost per agent invocation, useful for estimating operational expenses at scale.\n",
        "* **Cost Breakdown**: Detailed cost analysis for specific operations:\n",
        "    * Individual LLM calls with their token usage (input/output tokens) and associated costs\n",
        "    * Tool execution costs (if applicable)\n",
        "    * Per-operation cost breakdown showing which operations consume the most resources\n",
        "\n",
        "For a News Summary Agent, understanding the usage summary helps identify:\n",
        "- **Cost optimization opportunities**: If certain operations (e.g., LLM calls or news fetching) are consuming excessive resources\n",
        "- **Token usage patterns**: Track how many tokens are used for news summarization tasks\n",
        "- **Operational expenses**: Estimate costs at scale for news summary generation\n",
        "- **Model selection**: Make informed decisions about model selection and usage optimization to balance cost and quality"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3c3b6be",
      "metadata": {
        "id": "a3c3b6be"
      },
      "source": [
        "## 13. Summary of News Summary Agent Usage Metric Evaluation Notebook\n",
        "\n",
        "This notebook demonstrates the professional methodology for evaluating the usage and cost metrics of a **News Summary Agent** built with **Flotorch ADK** using the **Flotorch Eval framework**.\n",
        "\n",
        "**Use Case**: News Summary Agent - Fetches and summarizes the latest news using news APIs (e.g., NewsAPI).\n",
        "\n",
        "**Evaluation Metric**: usage_summary\n",
        "\n",
        "## Core Process\n",
        "\n",
        "### 1. Setup and Instrumentation\n",
        "- Configure a `FlotorchADKAgent` with custom tools (e.g., a news fetching function that uses NewsAPI).\n",
        "- Enable **OpenTelemetry Tracing** via the `tracer_config`.\n",
        "- This instrumentation allows detailed capture of token usage and cost data for all operations.\n",
        "\n",
        "### 2. Execution and Data Generation\n",
        "- Run a sample news query through the agent using the **Runner**.\n",
        "- This automatically generates an **Agent Trajectory** in the form of OpenTelemetry traces.\n",
        "- The trace records the usage and cost of each component, including:\n",
        "  - LLM calls (input/output tokens)\n",
        "  - Tool executions (news fetching)\n",
        "  - Step-by-step agent operations\n",
        "\n",
        "### 3. Evaluation\n",
        "- Use the `AgentEvaluator` client along with the specialized **UsageMetric** from `flotorch-eval`.\n",
        "- The evaluator processes the trace data to compute usage and cost statistics using the **usage_summary** metric.\n",
        "\n",
        "### 4. Analysis\n",
        "- The notebook displays a thorough usage and cost breakdown, including:\n",
        "  - **Total Cost**\n",
        "  - **Average Cost per Call**\n",
        "  - Cost breakdown for individual operations:\n",
        "    - LLM calls with token counts\n",
        "    - Tool executions\n",
        "    - Per-operation cost analysis\n",
        "\n",
        "## Purpose and Benefits\n",
        "\n",
        "This evaluation provides **actionable cost and usage metrics** that help developers:\n",
        "\n",
        "- Monitor and optimize operational costs for the News Summary Agent  \n",
        "- Track token usage patterns in news summarization tasks  \n",
        "- Identify expensive operations and optimize them  \n",
        "- Make informed decisions about model selection and usage optimization  \n",
        "- Estimate costs at scale for news summary generation"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
