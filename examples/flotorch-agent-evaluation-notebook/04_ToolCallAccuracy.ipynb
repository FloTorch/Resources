{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dsNdA9GGnqZq",
      "metadata": {
        "id": "dsNdA9GGnqZq"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://drive.google.com/drive/folders/1IrwoNrb3AWLAhAqjlAkJNYa39p9eT9ui?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e0202c9",
      "metadata": {
        "id": "5e0202c9"
      },
      "source": [
        "# Flotorch Agent Tool Call Accuracy Evaluation (Live Weather Agent Use Case)\n",
        "\n",
        "This notebook demonstrates how to measure and analyze the **tool call accuracy** of a **Flotorch ADK agent** (configured as a **Live Weather Agent** that delivers real-time weather forecasts and data via API integration) using the **Flotorch Eval** framework.\n",
        "\n",
        "The evaluation relies on **OpenTelemetry Traces** generated during the agent's run to assess the accuracy and appropriateness of tool usage decisions.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Concepts\n",
        "\n",
        "* **Live Weather Agent**: An agent designed to deliver real-time weather forecasts and data via API integration.\n",
        "* **OpenTelemetry Traces**: Detailed records of the agent's execution steps (spans) used to analyze tool call decisions and accuracy.\n",
        "* **ToolCallAccuracy**: A Flotorch Eval metric that evaluates the accuracy and appropriateness of tool usage decisions. The evaluation metric used is **toolcall_accuracy**.\n",
        "\n",
        "---\n",
        "### Architecture Overview\n",
        "\n",
        "![Workflow Diagram](diagrams/04_ToolCallAccuracy_Workflow_Diagram.drawio.png)\n",
        "*Figure 2: Detailed workflow diagram showing the step-by-step process of tool call accuracy evaluation from agent execution through trace collection to metric computation.*\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Requirements\n",
        "\n",
        "* Flotorch account with configured models.\n",
        "* Valid Flotorch API key and gateway base URL.\n",
        "* Agent configured with OpenTelemetry tracing enabled.\n",
        "* External API access for weather data (e.g., Open-Meteo API).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae050fdc",
      "metadata": {},
      "source": [
        "## Agent Setup in Flotorch Console\n",
        "\n",
        "**Important**: Before running this notebook, you need to create an agent in the Flotorch Console. This section provides step-by-step instructions on how to set up the agent.\n",
        "\n",
        "### Step 1: Access Flotorch Console\n",
        "\n",
        "1. **Log in to Flotorch Console**:\n",
        "   - Navigate to your Flotorch Console (e.g., `https://dev-console.flotorch.cloud`)\n",
        "   - Ensure you have the necessary permissions to create agents\n",
        "\n",
        "2. **Navigate to Agents Section**:\n",
        "   - Click on **\"Agents\"** in the left sidebar\n",
        "   - You should see the \"Agent Builder\" option selected\n",
        "\n",
        "### Step 2: Create New Agent\n",
        "\n",
        "1. **Click \"Create FloTorch Agent\"**:\n",
        "   - Look for the blue **\"+ Create FloTorch Agent\"** button in the top right corner\n",
        "   - Click it to start creating a new agent\n",
        "\n",
        "2. **Agent Configuration**:\n",
        "   - **Agent Name**: Choose a unique name for your agent (e.g., `toolcall-agent`)\n",
        "     - **Important**: The name should only contain alphanumeric characters and dashes (a-z, A-Z, 0-9, -)\n",
        "     - **Note**: Copy this agent name - you'll need to use it in the `agent_name` variable later\n",
        "   - **Description** (Optional): Add a description if desired\n",
        "\n",
        "### Step 3: Configure Agent Details\n",
        "\n",
        "After creating the agent, you'll be directed to the agent configuration page. Configure the following:\n",
        "\n",
        "#### Required Configuration:\n",
        "\n",
        "1. **Model** (`* Model`):\n",
        "   - **Required**: Select a model from the available options\n",
        "   - Example: `gpt-model` or any available model from your Flotorch gateway\n",
        "   - Click the edit icon to configure\n",
        "\n",
        "2. **Agent Details** (`* Agent Details`):\n",
        "   - **Required**: Configure agent details\n",
        "   - **System Prompt**: Copy and paste the following system prompt:\n",
        "\n",
        "you are the helpful assistant. you need call the get_weather tool when user ask about the weather.\n",
        "\n",
        "Available tools:\n",
        "1.get_weather\n",
        "\n",
        "\n",
        "   - **Goal**: Copy and paste the following goal:\n",
        "   \n",
        "you are the helpful assistant. you need call the get_weather tool when user ask about the weather.\n",
        "\n",
        "\n",
        "#### Optional Configuration:\n",
        "\n",
        "1. **Tools**:\n",
        "   - Tools will be added programmatically via the notebook (see Section 8)\n",
        "   - You can leave this as \"Not Configured\" in the console\n",
        "\n",
        "2. **Input Schema**:\n",
        "   - Optional: Leave as \"Not Configured\" for this use case\n",
        "\n",
        "3. **Output Schema**:\n",
        "   - Optional: Leave as \"Not Configured\" for this use case\n",
        "\n",
        "### Step 4: Publish the Agent\n",
        "\n",
        "1. **Review Configuration**:\n",
        "   - Ensure the Model and Agent Details are configured correctly\n",
        "   - Verify the System Prompt and Goal are set\n",
        "\n",
        "2. **Publish Agent**:\n",
        "   - After configuration, click **\"Publish\"** or **\"Make a revision\"** to publish the agent\n",
        "   - Once published, the agent will have a version number (e.g., v1)\n",
        "\n",
        "3. **Note the Agent Name**:\n",
        "   - **Important**: Copy the exact agent name you used when creating the agent\n",
        "   - You will need to replace `<your_agent_name>` in the `agent_name` variable in Section 2.1 (Global Provider Models and Agent Configuration)\n",
        "\n",
        "### Step 5: Update Notebook Configuration\n",
        "\n",
        "1. **Update Agent Name**:\n",
        "   - Navigate to Section 2.1 in this notebook\n",
        "   - Find the `agent_name` variable\n",
        "   - Replace `<your_agent_name>` with the exact agent name you created in the console\n",
        "\n",
        "**Example**:\n",
        "- If you created an agent named `toolcall-agent` in the console\n",
        "- Set `agent_name = \"toolcall-agent\"` in the notebook\n",
        "\n",
        "### Summary of Required vs Optional Settings\n",
        "\n",
        "| Setting | Required/Optional | Value |\n",
        "|---------|------------------|-------|\n",
        "| **Agent Name** | **Required** | Choose a unique name (copy it for notebook) |\n",
        "| **Model** | **Required** | Select from available models |\n",
        "| **System Prompt** | **Required** | Use the system prompt provided above |\n",
        "| **Goal** | **Required** | Use the goal provided above |\n",
        "| **Tools** | **Optional** | Will be added via notebook code |\n",
        "| **Input Schema** | **Optional** | Can leave as \"Not Configured\" |\n",
        "| **Output Schema** | **Optional** | Can leave as \"Not Configured\" |\n",
        "\n",
        "**Note**: The tools (Knowledge Base, Web Search, Weather, News) will be added to the agent programmatically in the notebook code, so you don't need to configure them manually in the console.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87732d23",
      "metadata": {
        "id": "87732d23"
      },
      "source": [
        "## 1. Setup and Installation\n",
        "\n",
        "### Purpose\n",
        "Install the necessary packages for the Flotorch Evaluation framework required for tool call accuracy evaluation.\n",
        "\n",
        "### Key Components\n",
        "- **`flotorch-eval`**: Flotorch evaluation framework with all dependencies for tool call accuracy metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o63iDPTETPci",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o63iDPTETPci",
        "outputId": "2ddebac7-3983-46e1-c53c-29f44c217ec0"
      },
      "outputs": [],
      "source": [
        "# Install Flotorch Eval packages\n",
        "# flotorch-eval: Flotorch evaluation framework with all dependencies\n",
        "\n",
        "%pip install flotorch-eval==2.0.0b1 flotorch[adk]==3.1.0b1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "578d5563",
      "metadata": {
        "id": "578d5563"
      },
      "source": [
        "## 2.Authentication and Credentials\n",
        "\n",
        "### Purpose\n",
        "Configure your Flotorch API credentials and gateway URL for authentication.\n",
        "\n",
        "### Key Components\n",
        "This cell configures the essential authentication and connection parameters:\n",
        "\n",
        "**Authentication Parameters**:\n",
        "\n",
        "| Parameter | Description | Example |\n",
        "|-----------|-------------|---------|\n",
        "| `FLOTORCH_API_KEY` | Your API authentication key (found in your Flotorch Console). Securely entered using `getpass` to avoid displaying in the notebook | `sk_...` |\n",
        "| `FLOTORCH_BASE_URL` | Your Flotorch gateway endpoint URL | `https://dev-console.flotorch.cloud` |\n",
        "\n",
        "**Note**: Use secure credential management in production environments.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d68ebc2",
      "metadata": {
        "id": "0d68ebc2"
      },
      "outputs": [],
      "source": [
        "import getpass  # Securely prompt without echoing in Prefect/notebooks\n",
        "\n",
        "# authentication for Flotorch access\n",
        "try:\n",
        "    FLOTORCH_API_KEY = getpass.getpass(\"Paste your API key here: \")\n",
        "    print(f\"✓ FLOTORCH_API_KEY set successfully\")\n",
        "except getpass.GetPassWarning as e:\n",
        "    print(f\"Warning: {e}\")\n",
        "    FLOTORCH_API_KEY = \"\"\n",
        "    print(f\"✗ FLOTORCH_API_KEY not set\")\n",
        "\n",
        "FLOTORCH_BASE_URL = input(\"Paste your Flotorch Base URL here: \")  # Prefect gateway or cloud endpoint          || https://dev-console.flotorch.cloud\n",
        "print(f\"✓ FLOTORCH_BASE_URL set: {FLOTORCH_BASE_URL}\")\n",
        "\n",
        "print(\"✓ All credentials configured successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1c3775d",
      "metadata": {
        "id": "f1c3775d"
      },
      "source": [
        "### 2.1. Global Provider Models and Agent Configuration\n",
        "\n",
        "### Purpose\n",
        "Define available models from the Flotorch gateway and configure agent-specific parameters.\n",
        "\n",
        "### Key Components\n",
        "\n",
        "**Global Provider Models**: These are the available models from the Flotorch gateway that can be used for evaluation and agent operations:\n",
        "\n",
        "| Model Variable | Model Name | Description |\n",
        "|----------------|------------|-------------|\n",
        "| `MODEL_CLAUDE_HAIKU` | `flotorch/flotorch-claude-haiku-4-5` | Claude Haiku model via Flotorch gateway |\n",
        "| `MODEL_CLAUDE_SONNET` | `flotorch/flotorch-claude-sonnet-3-5-v2` | Claude Sonnet model via Flotorch gateway |\n",
        "| `MODEL_AWS_NOVA_PRO` | `flotorch/flotorch-aws-nova-pro` | AWS Nova Pro model via Flotorch gateway |\n",
        "| `MODEL_AWS_NOVA_LITE` | `flotorch/flotorch-aws-nova-lite` | AWS Nova Lite model via Flotorch gateway |\n",
        "| `MODEL_AWS_NOVA_MICRO` | `flotorch/flotorch-aws-nova-micro` | AWS Nova Micro model via Flotorch gateway |\n",
        "\n",
        "**Agent Configuration Parameters**:\n",
        "\n",
        "| Parameter | Description | Example |\n",
        "|-----------|-------------|---------|\n",
        "| `default_evaluator` | The LLM model used for evaluation (can use MODEL_* variables above) | `MODEL_CLAUDE_SONNET` or `flotorch/flotorch-model` |\n",
        "| `agent_name` | The name of your Flotorch ADK agent | `toolcall-agent` |\n",
        "| `app_name` | The application name identifier | `agent-evaluation-app-name_04` |\n",
        "| `user_id` | The user identifier | `agent-evaliation-user-04` |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29373306",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29373306",
        "outputId": "32aaad2c-de12-4bde-f12b-f7a14f347138"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Global Provider Models (Flotorch Gateway Models)\n",
        "# ============================================================================\n",
        "# These models are available from the Flotorch gateway and can be used\n",
        "# for evaluation, agent operations, and other tasks.\n",
        "\n",
        "MODEL_CLAUDE_HAIKU = \"flotorch/flotorch-claude-haiku-4-5\"\n",
        "MODEL_CLAUDE_SONNET = \"flotorch/flotorch-claude-sonnet-3-5-v2\"\n",
        "MODEL_AWS_NOVA_PRO = \"flotorch/flotorch-aws-nova-pro\"\n",
        "MODEL_AWS_NOVA_LITE = \"flotorch/flotorch-aws-nova-lite\"\n",
        "MODEL_AWS_NOVA_MICRO = \"flotorch/flotorch-aws-nova-micro\"\n",
        "\n",
        "print(\"✓ Global provider models defined\")\n",
        "\n",
        "# The LLM model used for evaluation.\n",
        "# Can be modified to use any MODEL_* constant above (e.g., MODEL_CLAUDE_SONNET, MODEL_AWS_NOVA_PRO)\n",
        "# You can use your own models from Flotorch Console as well\n",
        "default_evaluator = MODEL_CLAUDE_HAIKU\n",
        "\n",
        "agent_name = \"<your_agent_name>\"  # The name of your Flotorch ADK agent                                        || ex : toolcall-agent\n",
        "app_name = \"<your_app_name>\"  # The application name identifier                                                || ex : agent-evaluation-app-name_04\n",
        "user_id = \"<your_user_id>\"  # The user identifier                                                              || ex : agent-evaliation-user-04\n",
        "\n",
        "print(\"✓ Agent Configuration Parameter defined \")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99963dc0",
      "metadata": {
        "id": "99963dc0"
      },
      "source": [
        "## 3. Import Required Libraries\n",
        "\n",
        "### Purpose\n",
        "Import all required components for evaluating the Live Weather Agent tool call accuracy using Flotorch Eval.\n",
        "\n",
        "### Key Components\n",
        "- **`AgentEvaluator`**: Core client for agent evaluation orchestration and trace fetching\n",
        "- **`ToolCallAccuracy`**: Flotorch Eval metric that evaluates the accuracy and appropriateness of tool usage decisions\n",
        "- **`FlotorchADKAgent`**: Creates and configures Flotorch ADK agents with custom tools and tracing\n",
        "- **`FlotorchADKSession`**: Manages agent sessions for multi-turn conversations\n",
        "- **`Runner`**: Executes agent queries and coordinates the agent execution flow\n",
        "- **`FunctionTool`**: Wraps Python functions as tools that can be used by the agent\n",
        "- **`types`**: Google ADK types for creating message content and handling agent events\n",
        "- **`pandas`**: Data manipulation and display for formatted results tables\n",
        "- **`display`**: IPython display utility for rendering formatted outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d5345ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d5345ba",
        "outputId": "e55ae3f0-d70a-49ad-d4f9-9f7737afdfba"
      },
      "outputs": [],
      "source": [
        "# Required imports\n",
        "# Flotorch Eval components\n",
        "from flotorch_eval.agent_eval.core.client import AgentEvaluator\n",
        "from flotorch_eval.agent_eval.metrics.llm_evaluators import ToolCallAccuracy\n",
        "\n",
        "# Flotorch ADK components\n",
        "from flotorch.adk.agent import FlotorchADKAgent\n",
        "from flotorch.adk.sessions import FlotorchADKSession\n",
        "\n",
        "# Google ADK components\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.tools import FunctionTool\n",
        "from google.genai import types\n",
        "\n",
        "# Utilities\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "print(\"✓ Imported necessary libraries successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33d236c2",
      "metadata": {
        "id": "33d236c2"
      },
      "source": [
        "## 4. Live Weather Agent Setup\n",
        "\n",
        "### Purpose\n",
        "Set up the Live Weather Agent with OpenTelemetry tracing enabled to capture detailed execution data for tool call accuracy evaluation.\n",
        "\n",
        "### Key Components\n",
        "1. **FlotorchADKAgent** (`agent_client`):\n",
        "   - Initializes the agent for weather forecasting tasks\n",
        "   - Configures `tracer_config` with `enabled: True` and `sampling_rate: 1` to capture 100% of traces\n",
        "   - Essential for evaluation as traces contain complete tool call decision information\n",
        "2. **FlotorchADKSession** (`session_service`): Manages agent sessions for multi-turn conversations\n",
        "3. **Runner** (`runner`): Executes agent queries and coordinates the agent execution flow\n",
        "\n",
        "These components work together to run the Live Weather Agent and generate OpenTelemetry traces for tool call accuracy analysis.\n",
        "\n",
        "### Custom Tool: Weather API Integration\n",
        "\n",
        "The Live Weather Agent uses a custom tool (`get_weather`) that integrates with external APIs to retrieve real-time weather forecasts and data. This tool:\n",
        "- Accepts a city name as input\n",
        "- Uses Open-Meteo Geocoding API to convert city name to latitude/longitude\n",
        "- Fetches real-time weather data using Open-Meteo Weather API\n",
        "- Returns structured weather information including temperature, wind speed, and humidity\n",
        "- Handles errors gracefully with exception handling\n",
        "\n",
        "The tool is wrapped as a `FunctionTool` that can be used by the agent to deliver real-time weather forecasts and data via API integration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "882c2118",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "882c2118",
        "outputId": "a6dc8a80-6923-4e45-b15c-88eb056bdd99"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from typing import Dict, Any\n",
        "\n",
        "def get_weather(city_name: str) -> Dict[str, Any]:\n",
        "    \"\"\"Return latitude, longitude, and current weather for a given city name\n",
        "       using Open-Meteo's free Geocoding + Weather APIs.\n",
        "\n",
        "    Args:\n",
        "        city_name: The name of the city to get weather for\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing city information and current weather data\n",
        "    \"\"\"\n",
        "\n",
        "    # --- Step 1: Geocode city name to lat/lon ---\n",
        "    geo_url = \"https://geocoding-api.open-meteo.com/v1/search\"\n",
        "    geo_params = {\n",
        "        \"name\": city_name,\n",
        "        \"count\": 1,\n",
        "        \"language\": \"en\",\n",
        "        \"format\": \"json\"\n",
        "    }\n",
        "\n",
        "    geo_res = requests.get(geo_url, params=geo_params).json()\n",
        "\n",
        "    if \"results\" not in geo_res:\n",
        "        raise ValueError(f\"City '{city_name}' not found\")\n",
        "\n",
        "    city = geo_res[\"results\"][0]\n",
        "    lat = city[\"latitude\"]\n",
        "    lon = city[\"longitude\"]\n",
        "\n",
        "    # --- Step 2: Fetch real-time weather using lat/lon ---\n",
        "    weather_url = \"https://api.open-meteo.com/v1/forecast\"\n",
        "    weather_params = {\n",
        "        \"latitude\": lat,\n",
        "        \"longitude\": lon,\n",
        "        \"current\": \"temperature_2m,wind_speed_10m,relative_humidity_2m\"\n",
        "    }\n",
        "\n",
        "    weather_res = requests.get(weather_url, params=weather_params).json()\n",
        "    current_weather = weather_res.get(\"current\", {})\n",
        "\n",
        "    # --- Return neatly structured result ---\n",
        "    result =  {\n",
        "        \"city\": city[\"name\"],\n",
        "        \"country\": city.get(\"country\"),\n",
        "        \"latitude\": lat,\n",
        "        \"longitude\": lon,\n",
        "        \"weather\": current_weather\n",
        "    }\n",
        "\n",
        "    return result\n",
        "# Register the custom tool - FunctionTool will automatically infer the schema from the function\n",
        "tools = [FunctionTool(get_weather)]\n",
        "\n",
        "print(\"✓ Weather tool defined and registered successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c42916b",
      "metadata": {
        "id": "6c42916b"
      },
      "source": [
        "## 5. Agent and Runner Initialization\n",
        "\n",
        "### Purpose\n",
        "Set up the Flotorch ADK Agent and Runner with OpenTelemetry tracing enabled to capture detailed execution data for tool call accuracy evaluation.\n",
        "\n",
        "### Key Components\n",
        "1. **FlotorchADKAgent** (`agent_client`):\n",
        "   - Initializes the agent with custom weather API tools\n",
        "   - Configures `tracer_config` with `enabled: True` and `sampling_rate: 1` to capture 100% of traces\n",
        "   - Essential for evaluation as traces contain tool call decision information\n",
        "2. **FlotorchADKSession** (`session_service`): Manages agent sessions for multi-turn conversations\n",
        "3. **Runner** (`runner`): Executes agent queries and coordinates the agent execution flow\n",
        "\n",
        "These components work together to run the Live Weather Agent and generate OpenTelemetry traces for tool call accuracy analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4ea47ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4ea47ea",
        "outputId": "675878be-564f-4743-d930-0a1b4e179c49"
      },
      "outputs": [],
      "source": [
        "# Initialize Flotorch ADK Agent with tracing enabled\n",
        "agent_client = FlotorchADKAgent(\n",
        "    agent_name=agent_name,\n",
        "    custom_tools=tools,\n",
        "    base_url=FLOTORCH_BASE_URL,\n",
        "    api_key=FLOTORCH_API_KEY,\n",
        "    tracer_config={\n",
        "        \"enabled\": True,                                                   # Enable tracing for toolcall accuracy measurement\n",
        "        \"endpoint\": \"https://dev-observability.flotorch.cloud/v1/traces\",  # Dev observability OTLP HTTP endpoint (used by QA)\n",
        "        \"sampling_rate\": 1                                                 # Sample 100% of traces\n",
        "    }\n",
        ")\n",
        "agent = agent_client.get_agent()\n",
        "\n",
        "# Initialize session service\n",
        "session_service = FlotorchADKSession(\n",
        "    api_key=FLOTORCH_API_KEY,\n",
        "    base_url=FLOTORCH_BASE_URL,\n",
        ")\n",
        "\n",
        "# Create the ADK Runner to execute agent queries\n",
        "runner = Runner(\n",
        "    agent=agent,\n",
        "    app_name=app_name,\n",
        "    session_service=session_service\n",
        ")\n",
        "\n",
        "print(\"✓ Agent and runner and session initialized successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ed6bc1e",
      "metadata": {
        "id": "7ed6bc1e"
      },
      "source": [
        "## 6. Helper Function for Running a Query\n",
        "\n",
        "### Purpose\n",
        "Define a helper function that executes a single-turn query with the agent and extracts the final response. The agent execution is automatically traced for tool call accuracy evaluation.\n",
        "\n",
        "### Functionality\n",
        "The `run_single_turn` function:\n",
        "- Accepts a `Runner`, query string, session ID, and user ID as parameters\n",
        "- Creates a user message using Google ADK types\n",
        "- Executes the query through the runner\n",
        "- Iterates through events to find and return the final agent response\n",
        "- Returns a fallback message if no response is found\n",
        "\n",
        "This function simplifies the process of running queries and ensures trace generation during execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b51ef384",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b51ef384",
        "outputId": "03593585-8b27-4080-fd7c-ff2e6296c170"
      },
      "outputs": [],
      "source": [
        "def run_single_turn(runner: Runner, query: str, session_id: str, user_id: str) -> str:\n",
        "    \"\"\"\n",
        "    Execute a single-turn query with the agent and return the final response.\n",
        "    The agent execution is traced automatically.\n",
        "    \"\"\"\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
        "    events = runner.run(user_id=user_id, session_id=session_id, new_message=content)\n",
        "\n",
        "    # Extract the final response\n",
        "    for event in events:\n",
        "        if event.is_final_response() and event.content and event.content.parts:\n",
        "            return event.content.parts[0].text\n",
        "    return \"No response from agent.\"\n",
        "\n",
        "print(\"✓ Helper function defined successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f3f4acd",
      "metadata": {
        "id": "0f3f4acd"
      },
      "source": [
        "## 7. Define Query\n",
        "\n",
        "### Purpose\n",
        "Define the sample weather query that will be executed by the Live Weather Agent to generate OpenTelemetry traces for tool call accuracy evaluation.\n",
        "\n",
        "### Key Components\n",
        "- **`query`**: A sample weather question that will be processed by the agent\n",
        "  - This query will trigger the agent to use weather API tools to fetch real-time weather data\n",
        "  - The query will test the agent's ability to make appropriate tool call decisions (e.g., selecting the correct weather API tool, passing appropriate parameters)\n",
        "  - The execution will be automatically traced to capture tool call decisions and execution\n",
        "  - The tool calls will be evaluated for accuracy and appropriateness using the ToolCallAccuracy metric\n",
        "  - Example: \"what is the weather in the hyderbad\"\n",
        "\n",
        "The query can be modified to test different weather scenarios and evaluate tool call accuracy for various types of weather-related questions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccab8cfa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccab8cfa",
        "outputId": "49bc44de-d9d7-4837-b556-151a2dc94dc2"
      },
      "outputs": [],
      "source": [
        "# Execute the query to generate traces\n",
        "query = \"what is the weather in the hyderbad\"\n",
        "\n",
        "print(f\"✓ Query defined: {query}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5742fdf",
      "metadata": {
        "id": "c5742fdf"
      },
      "source": [
        "## 8. Run the Query and Get Trace ID\n",
        "\n",
        "### Purpose\n",
        "Execute a sample query with the Live Weather Agent to generate OpenTelemetry traces that contain tool call decision data for evaluation.\n",
        "\n",
        "### Process\n",
        "1. **Create Session**: Initialize a new session for the agent interaction\n",
        "2. **Execute Query**: Run a sample query (e.g., \"what is the weather in the hyderabad\") through the agent\n",
        "3. **Retrieve Trace IDs**: Extract the generated trace IDs from the agent client\n",
        "4. **Display Results**: Print the agent response and trace ID for verification\n",
        "\n",
        "The execution automatically generates OpenTelemetry traces that record tool call decisions and execution information, which will be used for tool call accuracy evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f98ad20c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f98ad20c",
        "outputId": "1d0435fc-cc75-49f6-8294-067285caeaa7"
      },
      "outputs": [],
      "source": [
        "# Create a new session\n",
        "session = await runner.session_service.create_session(\n",
        "    app_name=app_name,\n",
        "    user_id=user_id,\n",
        ")\n",
        "print(f\"Session created: {session.id}\")\n",
        "\n",
        "response = run_single_turn(\n",
        "    runner=runner,\n",
        "    query=query,\n",
        "    session_id=session.id,\n",
        "    user_id=user_id\n",
        ")\n",
        "\n",
        "# Retrieve the generated trace IDs\n",
        "trace_ids = agent_client.get_tracer_ids()\n",
        "print(trace_ids)\n",
        "print(\"Agent Response:\")\n",
        "print(response[:200] + \"...\" if len(response) > 200 else response)\n",
        "print(f\"Found {len(trace_ids)} trace(s). First trace ID: {trace_ids[0] if trace_ids else 'N/A'}\")\n",
        "\n",
        "print(f\"✓ Query execution completed successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "812a9b9a",
      "metadata": {
        "id": "812a9b9a"
      },
      "source": [
        "## 9. Tool Call Accuracy Evaluation with Flotorch Eval\n",
        "\n",
        "### Purpose\n",
        "Initialize the `AgentEvaluator`, fetch the OpenTelemetry trace, and run the `ToolCallAccuracy` metric to evaluate tool call decision accuracy. The evaluation metric **toolcall_accuracy** provides detailed assessment of tool usage decisions for the Live Weather Agent.\n",
        "\n",
        "### Key Components\n",
        "1. **ToolCallAccuracy**: Initializes the tool call accuracy metric that will analyze trace data\n",
        "2. **AgentEvaluator** (`client`):\n",
        "   - Connects to the Flotorch gateway using API credentials\n",
        "   - Configured with a default evaluator model\n",
        "   - Provides methods to fetch and evaluate traces\n",
        "3. **Trace Fetching**: Retrieves the complete trace data using the trace ID generated during agent execution\n",
        "\n",
        "The fetched trace contains detailed information about tool call decisions and execution, which will be analyzed by the ToolCallAccuracy metric to compute the toolcall_accuracy score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0c963e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0c963e4",
        "outputId": "b4966651-e11d-4018-a339-cb2b7abd5fad"
      },
      "outputs": [],
      "source": [
        "# Initialize the ToolCallAccuracy metric\n",
        "metrics = [ToolCallAccuracy()]\n",
        "\n",
        "# Initialize the AgentEvaluator client\n",
        "client = AgentEvaluator(\n",
        "    api_key=FLOTORCH_API_KEY,\n",
        "    base_url=FLOTORCH_BASE_URL,\n",
        "    default_evaluator=default_evaluator\n",
        ")\n",
        "\n",
        "traces = None\n",
        "if trace_ids:\n",
        "    # Fetch the trace data from the Flotorch gateway\n",
        "    traces = client.fetch_traces(trace_ids[0])\n",
        "    print(f\"✓ Trace fetched successfully\")\n",
        "else:\n",
        "    print(\"✗ No trace IDs found to fetch.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "218e8814",
      "metadata": {
        "id": "218e8814"
      },
      "source": [
        "## 10. Run Evaluation\n",
        "\n",
        "### Purpose\n",
        "Execute the tool call accuracy evaluation by processing the fetched OpenTelemetry trace using the ToolCallAccuracy metric to assess tool usage decisions.\n",
        "\n",
        "### Process\n",
        "- Calls `client.evaluate()` with the trace data and ToolCallAccuracy metric\n",
        "- The evaluator processes the trace to analyze tool call decisions and execution\n",
        "- Computes the **toolcall_accuracy** metric which includes:\n",
        "  - Accuracy score (0.0 to 1.0) indicating how appropriate tool usage was\n",
        "  - Detailed evaluation explanation of tool call decisions\n",
        "  - Assessment of tool selection, parameter accuracy, and timing\n",
        "- Returns evaluation results with trajectory ID and metric scores\n",
        "\n",
        "This step generates the tool call accuracy analysis that will be displayed in the next section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d832fc0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d832fc0",
        "outputId": "cfaa8315-d75d-48de-c3c1-1ee91cbbf8ad"
      },
      "outputs": [],
      "source": [
        "if 'traces' in locals() and traces:\n",
        "    # Evaluate the trace using the ToolCallAccuracy metric\n",
        "    results = await client.evaluate(\n",
        "        trace=traces,\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    print(\"✓ Evaluation completed successfully!\")\n",
        "else:\n",
        "    print(\"Cannot evaluate: No traces were available.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35e8da4c",
      "metadata": {
        "id": "35e8da4c"
      },
      "source": [
        "## 11. Display and Interpret Results\n",
        "\n",
        "### Purpose\n",
        "Define helper functions to format and display the evaluation output clearly, showing the toolcall_accuracy metric results in a readable format.\n",
        "\n",
        "### Functionality\n",
        "The `display_metrics` function:\n",
        "- Extracts the `toolcall_accuracy` metric from evaluation results\n",
        "- Formats the accuracy score and evaluation details\n",
        "- Creates a structured display showing:\n",
        "  - Tool Call Accuracy Score (0.0 to 1.0)\n",
        "  - Detailed evaluation explanation\n",
        "- Uses pandas DataFrame with styled formatting for clean presentation\n",
        "\n",
        "This function provides a user-friendly way to visualize tool call accuracy metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44a11561",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44a11561",
        "outputId": "fd40ccfc-18a1-4b90-e024-98b90d31494a"
      },
      "outputs": [],
      "source": [
        "def display_metrics(result):\n",
        "    \"\"\"\n",
        "    Display tool call accuracy metrics in a formatted table.\n",
        "    \"\"\"\n",
        "    # Find the toolcall_accuracy metric\n",
        "    metric = next((m for m in result.scores if m.name == \"toolcall_accuracy\"), None)\n",
        "    if not metric:\n",
        "        print(\"No toolcall_accuracy metric found.\")\n",
        "        return\n",
        "\n",
        "    # Extract metric details\n",
        "    d = metric.details\n",
        "\n",
        "    # Get the details string (which contains the evaluation explanation)\n",
        "    details_text = d.get(\"details\", \"No details available.\")\n",
        "\n",
        "    # Format the details string with better readability\n",
        "    details = f\"Score: {metric.score:.2f} / 1.0\\n\\nEvaluation Details:\\n{details_text}\"\n",
        "\n",
        "    # Create DataFrame for display\n",
        "    df = pd.DataFrame([{\n",
        "        \"Metric\": metric.name.replace(\"_\", \" \").title(),\n",
        "        \"Score\": f\"{metric.score:.2f}\",\n",
        "        \"Details\": details\n",
        "    }])\n",
        "\n",
        "    # Display DataFrame with multiline support\n",
        "    display(df.style.set_properties(\n",
        "        subset=['Details'],\n",
        "        **{'white-space': 'pre-wrap', 'text-align': 'left'}\n",
        "    ))\n",
        "\n",
        "print(\"✓ Display metrics function defined successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27de8dc3",
      "metadata": {
        "id": "27de8dc3"
      },
      "source": [
        "## 12. View Tool Call Accuracy Results\n",
        "\n",
        "### Purpose\n",
        "Display the tool call accuracy evaluation results in a formatted table showing the complete assessment for the Live Weather Agent.\n",
        "\n",
        "### Output\n",
        "The displayed table includes:\n",
        "- **Metric**: The evaluation metric name (toolcall_accuracy)\n",
        "- **Score**: The tool call accuracy score (0.0 to 1.0)\n",
        "- **Details**: Comprehensive evaluation showing:\n",
        "  - Accuracy score out of 1.0\n",
        "  - Detailed explanation of tool call decisions\n",
        "  - Assessment of tool selection, parameter accuracy, and timing appropriateness\n",
        "\n",
        "This visualization helps identify tool usage issues and optimize the agent's tool call decisions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d055ba70",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "d055ba70",
        "outputId": "d4c02fb3-cd72-4df8-b623-37a01a3bd948"
      },
      "outputs": [],
      "source": [
        "if 'results' in locals():\n",
        "    display_metrics(results)\n",
        "else:\n",
        "    print(\"No results object found. Please run sections 5 and 6 first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0401dec6",
      "metadata": {
        "id": "0401dec6"
      },
      "source": [
        "### Interpreting the Tool Call Accuracy Results\n",
        "\n",
        "The **toolcall_accuracy** metric is a vital tool for quality monitoring of the Live Weather Agent:\n",
        "\n",
        "* **Accuracy Score (0.0 to 1.0)**: Indicates how appropriate and accurate the agent's tool usage decisions were:\n",
        "    * **1.0**: Perfect tool call accuracy - tool selection, parameters, and timing were all appropriate\n",
        "    * **0.5-0.9**: Good accuracy with minor issues in tool selection or parameter formatting\n",
        "    * **0.0-0.4**: Poor accuracy - incorrect tool selection, wrong parameters, or inappropriate timing\n",
        "* **Evaluation Details**: Provides a detailed explanation of:\n",
        "    * **Tool Selection Appropriateness**: Whether the agent selected the correct tool for the task (e.g., using `get_weather` for weather queries)\n",
        "    * **Parameter Accuracy and Formatting**: Whether tool parameters were correctly formatted and accurate (e.g., city name properly extracted and passed)\n",
        "    * **Timing and Necessity**: Whether the tool call was made at the right time and was necessary for the task\n",
        "    * **Overall Quality**: Comprehensive assessment of tool usage decision quality\n",
        "\n",
        "For a Live Weather Agent, understanding tool call accuracy helps identify:\n",
        "- **Tool selection issues**: If the agent uses incorrect tools or fails to use tools when needed\n",
        "- **Parameter formatting problems**: If city names or other parameters are incorrectly extracted or formatted\n",
        "- **Timing optimization**: If tool calls are made unnecessarily or at inappropriate times\n",
        "- **Overall reliability**: Monitor accuracy to ensure the agent delivers accurate and reliable real-time weather data via proper API integration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3c3b6be",
      "metadata": {
        "id": "a3c3b6be"
      },
      "source": [
        "## 13. Summary of Agent Tool Call Accuracy Evaluation Notebook\n",
        "\n",
        "This notebook demonstrates the professional methodology for evaluating the tool call accuracy of a **Flotorch ADK Agent** (configured as a **Live Weather Agent** that delivers real-time weather forecasts and data via API integration) using the **Flotorch Eval framework**.\n",
        "\n",
        "**Use Case**: Live Weather Agent - Delivers real-time weather forecasts and data via API integration.\n",
        "\n",
        "**Evaluation Metric**: toolcall_accuracy\n",
        "\n",
        "## Core Process\n",
        "\n",
        "### 1. Setup and Instrumentation\n",
        "- Configure a `FlotorchADKAgent` with custom weather API tools (e.g., Open-Meteo weather API integration).\n",
        "- Enable **OpenTelemetry Tracing** via the `tracer_config`.\n",
        "- This instrumentation allows detailed capture of tool call decisions and execution information.\n",
        "\n",
        "### 2. Execution and Data Generation\n",
        "- Run a sample query through the agent using the **Runner**.\n",
        "- This automatically generates an **Agent Trajectory** in the form of OpenTelemetry traces.\n",
        "- The trace records tool call decisions and execution, including:\n",
        "  - Tool selection decisions\n",
        "  - Parameter accuracy\n",
        "  - Tool execution results\n",
        "  - Step-by-step agent operations\n",
        "\n",
        "### 3. Evaluation\n",
        "- Use the `AgentEvaluator` client along with the specialized **ToolCallAccuracy** metric from `flotorch-eval`.\n",
        "- The evaluator processes the trace data to compute tool call accuracy statistics using the **toolcall_accuracy** metric.\n",
        "\n",
        "### 4. Analysis\n",
        "- The notebook displays a thorough tool call accuracy assessment, including:\n",
        "  - **Accuracy Score** (0.0 to 1.0)\n",
        "  - **Evaluation Details** explaining tool usage decisions\n",
        "  - Assessment of tool selection, parameter accuracy, and timing\n",
        "\n",
        "## Purpose and Benefits\n",
        "\n",
        "This evaluation provides **actionable quality metrics** that help developers:\n",
        "\n",
        "- Identify tool call accuracy issues in the Live Weather Agent  \n",
        "- Optimize tool usage decisions, particularly API parameter formatting  \n",
        "- Track quality trends over time  \n",
        "- Ensure the Live Weather Agent delivers **accurate and reliable real-time weather data** via proper API integration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1eb27d83",
      "metadata": {
        "id": "1eb27d83"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
